<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SCH: INT: Collaborative Research: Assistive Integrative Support Tool for Retinopathy of Prematurity</AwardTitle>
    <AwardEffectiveDate>10/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2020</AwardExpirationDate>
    <AwardAmount>688207</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Aidong Zhang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Retinopathy of prematurity (ROP) is a leading cause of childhood visual loss worldwide, and the social burdens of infancy-acquired blindness are enormous. Early diagnosis is critically important for successful treatment, and can prevent most cases of blindness. However, lack of access to expert medical diagnosis and care, especially in rural areas, remains a growing healthcare challenge. In addition, clinical expertise in ROP is lacking, and medical professionals are struggling to meet the increasing need for ROP care. As point-of-care technologies for diagnosis and intervention are rapidly expanding, the potential ability to assess ROP severity from any location with an internet connection and a camera, even without immediate ophthalmologic consultation available, could significantly improve delivery of ROP care by identifying infants who are in most urgent need for referral and treatment. This would dramatically reduce the incidence of blindness without a proportionate increase in the need for human resources, which take many years to develop.&lt;br/&gt;&lt;br/&gt;This project develops a prototype assistive integrative support tool for ROP, featuring a modular design comprising: (a) image analysis, (b) information fusion of clinical, imaging, and diagnostic data, and (c) generative probabilistic and regression models with associated computationally efficient machine learning algorithms. The outcomes of the project include disease severity metrics and diagnostic estimates obtained through clinical evidence classifiers trained jointly over expert-generated labels. These labels consist of discrete diagnostic labels, as well as comparison outcomes of relative severity between pairs of images. Random process models for vessel tortuosity and diameter distributions over the retina, as well as patch-based vessel-free image analysis through the use of convolutional neural networks on the entire image, enhance and augment feature extraction. Moreover, incorporating severity comparison outcomes through novel hard and soft constraint methods force inferred severity to agree with ordinal information provided by experts and address inherent uncertainty in expert ground-truth labels. The above severity inference methods are evaluated and fine-tuned over a broad array of generative models, both through retrospective analysis, including cross-validation, longitudinal tests, and tests across multiple sites, as well as through prospective analysis, evaluating its real-world clinical impact.</AbstractNarration>
    <MinAmdLetterDate>07/27/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>07/27/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1622542</AwardID>
    <Investigator>
      <FirstName>Jayashree</FirstName>
      <LastName>Kalpathy-Cramer</LastName>
      <EmailAddress>kalpathy@nmr.mgh.harvard.edu</EmailAddress>
      <StartDate>07/27/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Massachusetts General Hospital</Name>
      <CityName>Somerville</CityName>
      <ZipCode>021450000</ZipCode>
      <PhoneNumber>8572821670</PhoneNumber>
      <StreetAddress>Research Management</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8018</Code>
      <Text>Smart and Connected Health</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>8018</Code>
      <Text>Smart and Connected Health</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8062</Code>
      <Text>SCH Type II: INT</Text>
    </ProgramReference>
  </Award>
</rootTag>
