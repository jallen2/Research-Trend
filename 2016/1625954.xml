<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: The structure of the ASL lexicon: Experimental and statistical evidence from a large lexical database (ASL-LEX)</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>02/29/2020</AwardExpirationDate>
    <AwardAmount>287454</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William J. Badecker</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This collaborative project will record and study the properties of lexical forms in American Sign Language. Almost everything we know about human language comes from the study of spoken languages. However, only by studying sign languages is it possible to discover which linguistic rules and constraints are universal to all human languages and which depend on the particular properties of an individual language. By studying sign languages researchers can uncover language patterns that are tied to the nature of the articulators (i.e., the hands vs. the vocal tract) or that are linked to the specific way a language is perceived (i.e., visually vs. auditorally). Researchers can also uncover language patterns that result from properties that systematically vary between spoken and signed languages, such as the high prevalence of iconic forms (words that resemble what they mean) in sign languages. Psychological and linguistic research on spoken languages has relied on lexical databases--repositories of information about the words of a language--to identify factors that influence how words are comprehended and produced, to understand how words are organized and structured in the mind and brain (in our "mental lexicon"), and to discover the linguistic patterns that are present in languages. Unfortunately however, there is currently no comparably large lexical database for American Sign Language (ASL), the sign language used by deaf and hearing people in the United States.&lt;br/&gt;&lt;br/&gt;A primary aim of this project is to create a large, searchable, and publically available database of approximately 2,500 ASL signs. The database (called ASL-LEX) will contain the following information for each sign: subjective frequency-of-use ratings, iconicity ratings from both deaf signers and hearing non-signers, sign duration measures, lexical category information (e.g., noun, verb, etc.), and codes for sign-based phonological features (e.g., location, handshape, movement) that can be used to calculate whether the form of a sign is relatively common (has many form 'neighbors') or relatively unique (has few 'neighbors'). A second aim is to use ASL-LEX to conduct the first quantitative analysis of the ASL lexicon in order to uncover regularities in the way that phonological features appear (or do not appear) in ASL signs and how these patterns are influenced by sign properties such as frequency and iconicity. A third aim is to conduct experiments to determine the psychological reality of these phonological patterns (e.g., do signers unconsciously know which patterns are common and which are rare?) and to discover how phonological and lexical properties impact how quickly a sign is recognized (using a novel sign recognition technique) and produced (using a picture-naming task). Data from these experiments and related materials (e.g. picture stimuli) will be made available to the public through ASL-LEX. These materials constitute essential tools that will allow scientists and educators to create well-controlled ASL stimuli for use in research and the classroom. ASL-LEX can also be used by educators and early intervention specialists to develop benchmarks for assessing vocabulary development in signing children, (e.g., do children know the most frequent signs?) and to support literacy development (e.g., to find sign-based "rhymes"). A parallel aim of the project is to increase the representation of deaf people in science by including deaf researchers on the project and by providing an accessible environment for deaf students to gain training and research experience.</AbstractNarration>
    <MinAmdLetterDate>08/12/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>08/12/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1625954</AwardID>
    <Investigator>
      <FirstName>Karen</FirstName>
      <LastName>Emmorey</LastName>
      <EmailAddress>kemmorey@mail.sdsu.edu</EmailAddress>
      <StartDate>08/12/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>San Diego State University Foundation</Name>
      <CityName>San Diego</CityName>
      <ZipCode>921822190</ZipCode>
      <PhoneNumber>6195945731</PhoneNumber>
      <StreetAddress>5250 Campanile Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7252</Code>
      <Text>Perception, Action and Cognition</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7298</Code>
      <Text>COLLABORATIVE RESEARCH</Text>
    </ProgramReference>
  </Award>
</rootTag>
