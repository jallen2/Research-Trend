<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CPS: Synergy: Image-Based Indoor Navigation for Visually Impaired Users</AwardTitle>
    <AwardEffectiveDate>02/01/2017</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2020</AwardExpirationDate>
    <AwardAmount>749993</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07010000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Chengshan Xiao</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Severe visual impairment and blindness preclude many essential activities of daily living. Among these is independent navigation in unfamiliar indoor spaces without the assistance of a sighted companion. We propose to develop PERCEPT-V: an organic vision-driven, smartphone-based indoor navigation system, in which the user can navigate in open spaces without requiring retrofit of the environment. When the user seeks to obtain navigation instructions to a chosen destination, the smartphone will record observations from multiple onboard sensors in order to perform user localization. Once the location and orientation of the user are estimated, they are used to calculate the coordinates of the navigation landmarks surrounding the user. The system can then provide directions to the chosen destination, as well as an optional description of the landmarks around the user.&lt;br/&gt;&lt;br/&gt;We will focus on addressing the cyber-physical systems technology shortcomings usually encountered in the development of indoor navigation systems. More specifically, our project will consider the following transformative aspects in the design of PERCEPT-V: (i) Image-Based Indoor Localization and Orientation: PERCEPT-V will feature new computer vision-based localization algorithms that reduce the dependence on highly controlled image capture and richly informative images, increasing the reliability of localization from images taken by blind subjects in crowded environments; (ii) Customized Navigation Instructions: PERCEPT-V will deliver customized navigation instructions for sight-impaired users that accounts for diverse levels of confidence and operator capabilities. A thorough final evaluation study featuring visually impaired participants will assess our hypotheses driving the design and refinements of PERCEPT-V using rigorous statistical analysis.</AbstractNarration>
    <MinAmdLetterDate>08/26/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>09/21/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1645737</AwardID>
    <Investigator>
      <FirstName>Aura</FirstName>
      <LastName>Ganz</LastName>
      <EmailAddress>ganz@ecs.umass.edu</EmailAddress>
      <StartDate>08/26/2016</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Marco</FirstName>
      <LastName>Duarte</LastName>
      <EmailAddress>mduarte@ecs.umass.edu</EmailAddress>
      <StartDate>08/26/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Massachusetts Amherst</Name>
      <CityName>AMHERST</CityName>
      <ZipCode>010039242</ZipCode>
      <PhoneNumber>4135450698</PhoneNumber>
      <StreetAddress>Research Administration Building</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7918</Code>
      <Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>153E</Code>
      <Text>Wireless comm &amp; sig processing</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7918</Code>
      <Text>CYBER-PHYSICAL SYSTEMS (CPS)</Text>
    </ProgramReference>
  </Award>
</rootTag>
