<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>XPS: EXPL: Write Locality Theory and Optimization for Hybrid Memory</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2019</AwardExpirationDate>
    <AwardAmount>299999</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Anindya Banerjee</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A limit on extreme scale computing is the capacity, speed, durability and most importantly, energy efficiency of memory. Persistent memory is a disruptive technology that drastically reduces memory cost and static power but introduces the problems of slow writes and limited write endurance. An effective solution is caching. However, existing caches have been designed for fast reads: they do not minimize the number of write backs from cache to memory. The intellectual merits of this project are sufficient theories and efficient techniques for optimal write caching in future systems that use persistent memory. Caching, in both software and hardware, is increasingly prevalent. Hardware caches serve most of the memory accesses on commodity machines as well as super computers. Software caches, e.g. Memcached used by Wikipedia and Facebook, serve most of the data requests from online users. The project's broader significance and importance are the broad benefits of cache optimization in scientific and consumer computing.&lt;br/&gt;&lt;br/&gt;This project develops the formal concept of write locality and the theory and techniques to characterize locality and optimize the cache. It has three parts. The first is write locality modeling, which includes a set of metrics that can derive the amount of modified data in cache and the write backs from cache to memory in cache of all sizes and degrees of sharing. The second is deductive optimization, which mathematically derives the cache performance of different task and data organizations and selects the best solution among a combinatorial number of choices. The last is system modeling and application optimization, which use write locality to model software and hardware cache and to optimize a program.</AbstractNarration>
    <MinAmdLetterDate>07/11/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>07/11/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1629376</AwardID>
    <Investigator>
      <FirstName>Chen</FirstName>
      <LastName>Ding</LastName>
      <EmailAddress>cding@cs.rochester.edu</EmailAddress>
      <StartDate>07/11/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Rochester</Name>
      <CityName>Rochester</CityName>
      <ZipCode>146270140</ZipCode>
      <PhoneNumber>5852754031</PhoneNumber>
      <StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8283</Code>
      <Text>Exploiting Parallel&amp;Scalabilty</Text>
    </ProgramElement>
  </Award>
</rootTag>
