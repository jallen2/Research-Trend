<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Additive Parts-based Data Representation with Nonnegative Sparse Autoencoders</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>233235</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07010000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Chengshan Xiao</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>One of the long-standing open problems of computational learning is its inability to produce solutions that are intuitively understandable. Because of the limited transparency, most computed predictions are not easily justifiable by humans who need to render final decisions. This project addresses this shortcoming of machine learning predictions by investigating a class of machine learning algorithms that mimics natural processing and leads to more interpretable representations of data. Such processing decomposes visual patterns or other data into parts through unsupervised learning and produces non-negative parts only. Since this approach allows only additive recombination of parts to reconstruct the original data, it mimics natural processing in human perception and cognition. The project advances novel data representation beyond standard computational learning approaches. Tests are conducted with planar images or tabulated data that describe specific domain of interest. The tests objectives are to produce useful and understandable features, logic rules or verbal explanations in lower dimensional space. &lt;br/&gt;&lt;br/&gt;This work aims at evaluating how rich data can be explored in order to be better understood. The novel paradigm is to generate non-negative, sparse and localized features and receptive fields within hierarchies of features. This is achieved through autoencoder-based transformations of visual images or of typical non-negative data matrices. The novel autoencoders are constrained to have non-negative weights. Specific conditions to be tested include pooling, rectifying-type activation functions of neurons and select norms of activations sparsity. The project advances the following transformational challenges at the intersection of computational and human systems: (1) Representation of data with non-negative encodings only, (2) Complexity of layers and of receptive filters (more simpler filters vs. fewer complex filters), (3) Choice of the number of layers, also in the context of hyper-parameter tuning, (4) Pooling for non-negative processing, (5) Connections between the autoencoder-based learning and related biological evidence, and finally (6) Ability to generate explanations or understandable rules for select domains</AbstractNarration>
    <MinAmdLetterDate>07/28/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>07/28/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1641042</AwardID>
    <Investigator>
      <FirstName>Tamer</FirstName>
      <LastName>Inanc</LastName>
      <EmailAddress>t.inanc@louisville.edu</EmailAddress>
      <StartDate>07/28/2016</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Jacek</FirstName>
      <LastName>Zurada</LastName>
      <EmailAddress>jmzura02@louisville.edu</EmailAddress>
      <StartDate>07/28/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Louisville Research Foundation Inc</Name>
      <CityName>Louisville</CityName>
      <ZipCode>402021959</ZipCode>
      <PhoneNumber>5028523788</PhoneNumber>
      <StreetAddress>The Nucleus</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Kentucky</StateName>
      <StateCode>KY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7564</Code>
      <Text>COMMS, CIRCUITS &amp; SENS SYS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
