<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: Unraveling and Building Top-Down Generators in Deep Convolutional Neural Networks</AwardTitle>
    <AwardEffectiveDate>07/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2019</AwardExpirationDate>
    <AwardAmount>449999</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Aude Oliva</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Deep learning has recently significantly advanced research fields that are closely related to artificial intelligence. The fundamental problem of knowledge representation however remains open and the role of top-down process in deep learning is yet not very clear. For example, to train a deep learning algorithm to detect simply the translation of a dog in an image, a data-driven way of training deep learning would require generating thousands of samples by moving the dog around in the image. However, a top-down model, if available, can directly detect translation using two variables along the axes. The main goal of this project is to explore a path to discover, learn, and build embedded deep learning models, accounting for a rich family of top-down spatial transformation and geometric composition in convolutional neural networks. The resulting models provide a transparent way of understanding the embedded top-down transformation process through neural network layers. The learned neurally-inspired top-down knowledge representation will benefit studies across multiple disciplines, including visual perception, brain sciences, cognitive modeling, and decision making. &lt;br/&gt;&lt;br/&gt;The current practice in deep learning, for example convolutional neural networks (CNN), is largely dominated by data-driven bottom-up approaches. While the performances of various applications using convolutional neural networks (CNN) are impressive, there nevertheless exists a big gap between what bottom CNN can offer and what comprehensive intelligence requires. These strongly bottom-up CNN characteristics leave a big room for one to provide deep learning with the ability to also incorporate top-down information for effective knowledge representation, network learning, cognitive modeling, and visual inference. This project is about building a roadmap towards developing top-down generators. This is done by unraveling the role of explicit top-down knowledge representation and propagation, by studying the feature flows produced inside the convolutional neural networks, by building robust analysis-by-synthesis methods that combine top-down and bottom-up processes, and by creating explicit generative models to assist a wide range of applications. The benefit of studying the top-down generators to a broad family of applications is greatly intriguing, including but not limited to: creating network internal data augmentation, building object detection, developing scene understanding systems; modeling compositional and contextual object configurations; and performing zero-shot learning.</AbstractNarration>
    <MinAmdLetterDate>06/28/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>06/28/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1618477</AwardID>
    <Investigator>
      <FirstName>Zhuowen</FirstName>
      <LastName>Tu</LastName>
      <EmailAddress>zhuowen.tu@gmail.com</EmailAddress>
      <StartDate>06/28/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-San Diego</Name>
      <CityName>La Jolla</CityName>
      <ZipCode>920930934</ZipCode>
      <PhoneNumber>8585344896</PhoneNumber>
      <StreetAddress>Office of Contract &amp; Grant Admin</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8089</Code>
      <Text>Understanding the Brain/Cognitive Scienc</Text>
    </ProgramReference>
  </Award>
</rootTag>
