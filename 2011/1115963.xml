<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Interior-point algorithms for conic optimization with sparse matrix cone constraints</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2015</AwardExpirationDate>
    <AwardAmount>303100</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Junping Wang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Conic optimization is an extension of linear programming in which the &lt;br/&gt;componentwise vector inequalities are replaced by inequalities with &lt;br/&gt;respect to nonpolyhedral convex cones. The conic optimization model is &lt;br/&gt;widely used in the recent literature on convex optimization and provides&lt;br/&gt;an elegant framework for extending interior-point algorithms from linear &lt;br/&gt;programming to convex optimization. It is also the basis of popular &lt;br/&gt;modeling systems for convex optimization. &lt;br/&gt;The research on algorithms for conic optimization has mainly focused on &lt;br/&gt;three types of inequalities, associated with the nonnegative orthant, &lt;br/&gt;the second-order cone, and the positive semidefinite cone. &lt;br/&gt;This restriction is motivated by symmetry properties that can be exploited &lt;br/&gt;to formulate symmetric primal-dual interior-point algorithms.&lt;br/&gt;However, large gaps in linear algebra complexity exist between the &lt;br/&gt;three types of conic constraints, and this can lead to inefficiencies when &lt;br/&gt;convex optimization problems are converted to the standard conic format. &lt;br/&gt;This study considers approaches to improve the efficiency of conic optimization &lt;br/&gt;solvers by considering a larger class of conic constraints, &lt;br/&gt;defined by chordal sparse matrix cones, i.e., cones of positive &lt;br/&gt;semidefinite matrices with a given chordal sparsity pattern, &lt;br/&gt;and the associated dual cones of chordal sparse matrices that &lt;br/&gt;have a positive semidefinite completion. These cones include as special &lt;br/&gt;cases the three standard cones, but also several interesting non-self-dual &lt;br/&gt;cones. Moreover non-chordal sparsity patterns can often be efficiently &lt;br/&gt;embedded in chordal patterns and, as a consequence, sparse semidefinite &lt;br/&gt;programs can be solved as non-symmetric cone programs involving &lt;br/&gt;lower-dimensional cones than the positive semidefinite cone used in &lt;br/&gt;semidefinite programming methods. The choice for chordal matrix cones is &lt;br/&gt;further motivated by the existence of fast algorithms for evaluating the &lt;br/&gt;associated barrier functions and their derivatives.&lt;br/&gt;The investigator and his collaborators study nonsymmetric &lt;br/&gt;interior-point algorithms for sparse matrix cones, building on techniques &lt;br/&gt;developed for large-scale sparse matrix computations, in particular, &lt;br/&gt;multifrontal and supernodal factorization algorithms and parallel sparse &lt;br/&gt;matrix algorithms.&lt;br/&gt;&lt;br/&gt;A wide variety of practical problems in engineering and science can be &lt;br/&gt;formulated as nonlinear convex optimization problems, and solved using &lt;br/&gt;algorithms developed over the last few decades. &lt;br/&gt;The success of these techniques has created a demand for robust and &lt;br/&gt;efficient algorithms for very large convex optimization problems, &lt;br/&gt;especially for applications in machine learning, computer vision, &lt;br/&gt;electronic design automation, sensor networks, and combinatorial &lt;br/&gt;optimization. The problem sizes that arise in these fields often &lt;br/&gt;exceed the capabilities of general-purpose solvers. &lt;br/&gt;The work of the prinicipal investigator with his collaborators considers approaches to improve the scalability of interior-point&lt;br/&gt;algorithms, an important class of convex optimization algorithms.&lt;br/&gt;Freely available high-quality software implementations of the techniques developed in the&lt;br/&gt;project are a product of the research.</AbstractNarration>
    <MinAmdLetterDate>06/06/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>06/06/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1115963</AwardID>
    <Investigator>
      <FirstName>Lieven</FirstName>
      <LastName>Vandenberghe</LastName>
      <EmailAddress>vandenbe@ee.ucla.edu</EmailAddress>
      <StartDate>06/06/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Los Angeles</Name>
      <CityName>LOS ANGELES</CityName>
      <ZipCode>900951406</ZipCode>
      <PhoneNumber>3107940102</PhoneNumber>
      <StreetAddress>10889 Wilshire Boulevard</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1271</Code>
      <Text>COMPUTATIONAL MATHEMATICS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9263</Code>
      <Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
    </ProgramReference>
  </Award>
</rootTag>
