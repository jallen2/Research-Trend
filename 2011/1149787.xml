<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Multimodal and Multialgorithm Facial Activity Understanding by Audiovisual Information Fusion</AwardTitle>
    <AwardEffectiveDate>03/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2018</AwardExpirationDate>
    <AwardAmount>443803</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project develops a unified multimodal and multialgorithm fusion framework to recognize facial action units, which describe complex and rich facial behaviors. The information from voice is incorporated with visual observations to effectively improve facial activity understanding since voice and facial activity are intrinsically correlated. The developed framework systematically captures the inherent interactions between the visual and audio channels in a global context of human perception of facial behavior. Advanced machine learning techniques are developed to integrate these relationships together with uncertainties associated with various visual and audio measurements in the fusion framework to achieve a robust and accurate understanding of facial activity. It is these coordinated and consistent interactions that produce a meaningful facial display.&lt;br/&gt;&lt;br/&gt;The research work from this project fosters computer vision and machine learning technologies with applications across a wide range of fields varying from psychiatry to human-computer interaction. The new audiovisual emotional database constructed in this research facilitates benchmark evaluations and promotes new research directions, especially, in human behavior analysis. An integration of research and education promotes cutting-edge training on human-computer interactions to K-12, undergraduate, and graduate students, especially encourages the participation of women in engineering and computing.</AbstractNarration>
    <MinAmdLetterDate>02/27/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>02/27/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1149787</AwardID>
    <Investigator>
      <FirstName>Yan</FirstName>
      <LastName>Tong</LastName>
      <EmailAddress>tongy@cec.sc.edu</EmailAddress>
      <StartDate>02/27/2012</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University South Carolina Research Foundation</Name>
      <CityName>COLUMBIA</CityName>
      <ZipCode>292080001</ZipCode>
      <PhoneNumber>8037777093</PhoneNumber>
      <StreetAddress>1600 Hampton Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>South Carolina</StateName>
      <StateCode>SC</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
  </Award>
</rootTag>
