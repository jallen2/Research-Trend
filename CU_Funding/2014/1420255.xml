<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CHS: Small: Detecting Misinformation Flows in Social Media Spaces During Crisis Events</AwardTitle>
    <AwardEffectiveDate>09/15/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>515046</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>William Bainbridge</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This research seeks both to understand the patterns and mechanisms of the diffusion of misinformation on social media and to develop algorithms to automatically detect misinformation as events unfold. During natural disasters and other hazard events, individuals increasingly utilize social media to disseminate, search for and curate event-related information. Eyewitness accounts of event impacts can now be shared by those on the scene in a matter of seconds. There is great potential for this information to be used by affected communities and emergency responders to enhance situational awareness and improve decision-making, facilitating response activities and potentially saving lives. Yet several challenges remain; one is the generation and propagation of misinformation. Indeed, during recent disaster events, including Hurricane Sandy and the Boston Marathon bombings, the spread of misinformation via social media was noted as a significant problem; evidence suggests it spread both within and across social media sites as well as into the broader information space. &lt;br/&gt;&lt;br/&gt;Taking a novel and transformative approach, this project aims to utilize the collective intelligence of the crowd - the crowdwork of some social media users who challenge and correct questionable information - to distinguish misinformation and aid in its detection. It will both characterize the dynamics of misinformation flow online during crisis events, and develop a machine learning strategy for automatically identifying misinformation by leveraging the collective intelligence of the crowd. The project focuses on identifying distinctive behavioral patterns of social media users in both spreading and challenging or correcting misinformation. It incorporates qualitative and quantitative methods, including manual and machine-based content analysis, to look comprehensively at the spread of misinformation. The primary research site is Twitter, because it is public, it facilitates rapid information dissemination, and it has gained exposure as a highly used medium during disaster events. This investigation expands beyond Twitter to study information flows across other social media and the surrounding Internet by tracing URL links to their original sources. &lt;br/&gt;&lt;br/&gt;This research offers empirical, theoretical and applied contributions to the field of human-computer interaction in the areas of social computing, crisis informatics, and crowdsourcing. Empirically, it enhances our understanding of the flow of misinformation in online spaces. It builds on previous studies to include a more nuanced view of misinformation by examining several types of behavioral actions, including correction, speculation and challenges to misinformation. Moreover, the project maps information contagion within a particular social media network and across different platforms (using URL analysis) to identify patterns of information diffusion, or signatures, that can be used to detect and classify different types of misinformation. Theoretically, it contributes to a growing understanding of crowdwork, crowdsourcing, and collective intelligence within online social networks, specifically looking to understand and describe how the connected crowd performs as a massive sensor network that detects misinformation during crisis events. Finally, it aims to leverage these empirical and theoretical contributions to develop solutions for the real-time detection of misinformation on social media.</AbstractNarration>
    <MinAmdLetterDate>08/18/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>05/11/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1420255</AwardID>
    <Investigator>
      <FirstName>Emma</FirstName>
      <LastName>Spiro</LastName>
      <EmailAddress>espiro@uw.edu</EmailAddress>
      <StartDate>08/18/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Robert</FirstName>
      <LastName>Mason</LastName>
      <EmailAddress>rmmason@uw.edu</EmailAddress>
      <StartDate>08/18/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Kate</FirstName>
      <LastName>Starbird</LastName>
      <EmailAddress>kstarbi@uw.edu</EmailAddress>
      <StartDate>08/18/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Washington</Name>
      <CityName>Seattle</CityName>
      <ZipCode>981950001</ZipCode>
      <PhoneNumber>2065434043</PhoneNumber>
      <StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Washington</StateName>
      <StateCode>WA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
  </Award>
</rootTag>
