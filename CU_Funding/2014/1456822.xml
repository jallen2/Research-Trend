<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Visual Memory Mechanisms in Transsaccadic Integration and Overt Search</AwardTitle>
    <AwardEffectiveDate>03/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2018</AwardExpirationDate>
    <AwardAmount>424834</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Catherine Arrington</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A fundamental question in vision science concerns how people perceive a continuous visual environment before them when visual information enters the visual system through a series of brief glances interrupted by frequent rapid eye movements. Part of the answer may be that the visual system relies on a form of visual memory to allow for continuity between glances. In the present work, the research team will investigate how this type of visual memory operates. Achieving a better understanding of the basic operation of visual memory across eye movements could potentially lead to practical applications, such as optimized procedures for radiologists, baggage screeners, satellite image analysts, and others whose occupations require them to search for critical pieces of visual information during a visual search process. Another potential application could be optimized design of artificial vision systems. &lt;br/&gt;&lt;br/&gt;The proposed work aims to answer two basic questions regarding the operation of visual memory between glances. First, the research aims to investigate the capacity of such visual memory: How much visual information can this type of memory hold? Second, the research also aims to investigate how the capacity limitations of the visual memory mechanism constrain human performance in visual search tasks. For example, when the capacity of the visual memory is exceeded, how does this impact a person's ability to search for a specific piece of visual information that may be hidden among lots of other visual items? A set of rigorous computational and experimental techniques will be used to characterize the information contained within visual memory during visual search as well as to assess the impact of visual memory on visual search performance. The techniques will allow for detailed and novel quantitative predictions about how visual sensitivity and visual memory capacity interact to determine human performance in visual search tasks. Model predictions will be tested through psychophysical experiments.</AbstractNarration>
    <MinAmdLetterDate>02/27/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>02/27/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1456822</AwardID>
    <Investigator>
      <FirstName>Melchi</FirstName>
      <LastName>Michel</LastName>
      <EmailAddress>melchi.michel@rutgers.edu</EmailAddress>
      <StartDate>02/27/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Rutgers University New Brunswick</Name>
      <CityName>Piscataway</CityName>
      <ZipCode>088543925</ZipCode>
      <PhoneNumber>8489320150</PhoneNumber>
      <StreetAddress>33 Knightsbridge Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7252</Code>
      <Text>Perception, Action and Cognition</Text>
    </ProgramReference>
  </Award>
</rootTag>
