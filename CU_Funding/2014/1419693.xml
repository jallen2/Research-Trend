<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>III: Small: Understanding the Relevance of Text Passages</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>250000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>James French</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Some information retrieval (IR) queries can be best answered with a web page, others can be answered with a single fact or named entity. Many other queries could best be answered with a text passage and we propose to develop new techniques for this task that will be a significant improvement on the current state-of-the-art. Developing effective passage retrieval would have a major effect on search tools by greatly extending the range of queries that could be answered directly using text passages retrieved from the web. This is particularly important for mobile search applications with limited output bandwidth based on using either a small screen or speech output. In this case, the ability to use passages to reduce the amount of output while maintaining high relevance will be critical. &lt;br/&gt;&lt;br/&gt;We will study research issues that have either been ignored, or only partially addressed, in prior research, such as showing whether passages be better answers than documents for some queries, predicting which queries have good answers at the passage level, ranking passages to retrieve the best answers, and evaluating the effectiveness of passages as answers. To address these issues, we will develop new retrieval models that can define and rank "answers" for different text granularities such as sentences and passages, models of query properties that are associated with good passage-level answers, and models that differentiate between topicality and information content. Understanding the relevance of text passages will also involve obtaining new types of relevance assessments at passage granularity, and developing new evaluation metrics that combine relevance with the size of the result output. For further information see the project web site at: http://ciir.cs.umass.edu/research/answer_passages.</AbstractNarration>
    <MinAmdLetterDate>08/06/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/06/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1419693</AwardID>
    <Investigator>
      <FirstName>W. Bruce</FirstName>
      <LastName>Croft</LastName>
      <EmailAddress>croft@cs.umass.edu</EmailAddress>
      <StartDate>08/06/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Massachusetts Amherst</Name>
      <CityName>Hadley</CityName>
      <ZipCode>010359450</ZipCode>
      <PhoneNumber>4135450698</PhoneNumber>
      <StreetAddress>Research Administration Building</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7364</Code>
      <Text>INFO INTEGRATION &amp; INFORMATICS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7364</Code>
      <Text>INFO INTEGRATION &amp; INFORMATICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
