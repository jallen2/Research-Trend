<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CHS: Small: Collaborative Research: Development of a Wearable 3D Integral Imaging Augmented Reality Display Technology</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>250000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>An augmented reality (AR) display which enables the ability to overlay 2D or 3D digital information on a person's real-world view has long been portrayed as a technology that will transform the way that people perceive and interact with digital information. Although several types of display devices have been explored for AR applications, the ideal display would be a lightweight and compact optical-see-through head-mounted-display (OST-HMD) which enables digital information to be optically superposed onto the direct view of the physical world, and which at the same time maintains a see-through view of the world. With recent advances in mobile computing, image sensors, and cloud computing, the single remaining barrier to realizing ubiquitous AR technology is the display technology. The lack of high-performance, compact, and low-cost AR displays limits the ability to explore its potential benefits. One of the specific display problems that has not yet been adequately addressed, and is thus a specific barrier to widespread use of AR technology, is the visual discomfort and fatigue experiences by users of OST-HMDs. Visual discomfort is a critical concern in applications where users need to work with AR displays for an extended period of time. One of the key factors causing visual discomfort is the accommodation-convergence cue mismatch between digital information rendered by the display and the real-world scene. This is a fundamental problem inherent to existing AR displays. This project will address the human factor issues that persist in existing AR displays by developing a compact, lightweight, glasses-style 3D AR display technology that integrates wearable AR display technology with a microscopic integral imaging method. 3D products will soon pervade daily activities in education, transportation, computers, medicine, defense, and security. The U.S. has substantially contributed to the original innovative concepts for 3D imaging and 3D display, and will benefit from further development of 3D technologies, and from research and development in U.S. universities. This project, a collaboration between two experts in 3D vision technologies at two U.S. universities, will address the human factors issues that persist in existing AR displays. Project outcomes will readily transition to commercialization of new 3D displays, and will train of the next generation of experts in the field of 3D displays, who will contribute to industry, high tech firms, commerce, government, education, and health related fields.&lt;br/&gt;&lt;br/&gt;The key innovation of the project is that it will investigate and develop an innovative optical approach to OST-HMD design that uniquely integrates a 3D microscopic integral imaging (micro-InI) display and visualization method for full-parallax lightfield creation with an emerging optical design approach - freeform optical technology - for OST-HMD viewing optics. This approach enables the development of a compact 3D integral imaging optical see-through HMD with full-parallax lightfield rendering capability, which is anticipated to minimize the accommodation-convergence discrepancy problem plaguing existing AR displays, and thus substantially reduce the visual discomfort and fatigue for users. The project will design, develop, and implement a custom compact prototype system; develop system calibration and assessment methods; and perform preliminary user-based assessment experiments to evaluate the effects of our proposed technology on visual perception and visual fatigue.</AbstractNarration>
    <MinAmdLetterDate>08/20/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>07/28/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1422179</AwardID>
    <Investigator>
      <FirstName>Bahram</FirstName>
      <LastName>Javidi</LastName>
      <EmailAddress>bahram@engr.uconn.edu</EmailAddress>
      <StartDate>08/20/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Connecticut</Name>
      <CityName>Storrs</CityName>
      <ZipCode>062691133</ZipCode>
      <PhoneNumber>8604863622</PhoneNumber>
      <StreetAddress>438 Whitney Road Ext.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Connecticut</StateName>
      <StateCode>CT</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
