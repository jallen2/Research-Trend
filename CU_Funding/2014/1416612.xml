<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase I: Semantic Video Analysis for Video Summarization and Recommendation</AwardTitle>
    <AwardEffectiveDate>07/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2015</AwardExpirationDate>
    <AwardAmount>148754</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Peter Atherton</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is considerable because a variety of complementary new technologies is ushering in a new era in which visual messages are becoming a first-class media type along-side text and speech. Today, both amateur and professional videographers still have to enter the virtual darkroom to sift through video, edit it, and produce engaging content. Video creation is waiting for its Polaroid moment, when a technological solution will transform the post-production time required to create engaging video. If successful, the technology developed in this project will greatly increase the utility of any video capture device and would have implications outside of Internet media in areas such as life recording and knowledge transfer. The countless video clips of important or memorable events that are today commonly archived and forgotten could instead be automatically summarized and made available in a usable and engaging format. &lt;br/&gt;&lt;br/&gt;This Small Business Innovation Research (SBIR) Phase I project aims to evaluate the technical viability of an automatic video summarization system based on neural networks and adapted to measurements of human psychology. As people collectively record more videos than they can possibly consume (the video deluge problem), a technology that automatically turns raw videos into relevant and engaging summaries becomes increasingly critical. The company's proposed platform would streamline video sharing, search, and viewing, all of which are staples of our online lives. Scientifically we are at a unique time in the capabilities of artificial visual systems, with some systems rivaling human performance in limited domains. Furthermore, the field of visual psychology has also seen recent progress in relating visual semantic information to cognitive phenomena, like memorability of images. Taken together, it may now be possible to automatically predict the cognitive relevance of visual information and produce effective video summarizations. This project combines deep neural networks for visual object recognition, recurrent networks for contextually embedded temporal information, and user measurement of interest, memorability, and uniqueness. The primary technical objective is to determine whether a system can automatically predict human-produced video summarizations.</AbstractNarration>
    <MinAmdLetterDate>05/12/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>05/12/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1416612</AwardID>
    <Investigator>
      <FirstName>Charles</FirstName>
      <LastName>Cadieu</LastName>
      <EmailAddress>mgmt@baylabs.io</EmailAddress>
      <StartDate>05/12/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Bay Labs, Inc.</Name>
      <CityName>San Francisco</CityName>
      <ZipCode>941033734</ZipCode>
      <PhoneNumber>4154245616</PhoneNumber>
      <StreetAddress>1479 Folsom Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
  </Award>
</rootTag>
