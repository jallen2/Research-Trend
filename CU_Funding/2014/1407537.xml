<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Non-gaussian graphical models via additive conditional independence and nonlinear dimension reduction</AwardTitle>
    <AwardEffectiveDate>07/15/2014</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2017</AwardExpirationDate>
    <AwardAmount>210000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gabor J. Szekely</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Statistical networks and graphical models are two of the most important components of contemporary data analysis. They have important applications in Genomics, sociology, machine learning, study of the internet, and homeland security. Current statistical graphical models require strong assumptions in order to be computationally feasible for estimating large-scale networks but these assumptions also severely limit their applications. In this project the principal investigator will lay out the groundwork for developing a new class of statistical graphical models that do not rely on these strong assumptions but at the same time retain the computational simplicity of the current models. The new class of models will greatly expand the scope and capability of current methods for analyzing networks that are becoming increasingly prevalent in modern applications.&lt;br/&gt;&lt;br/&gt;In this project the principal investigator will develop a class of nonparametric graphical models that avoid the Gaussian or copula Gaussian assumptions. This new class of models can handle intrinsically nonlinear interactions that cannot be captured by a copula Gaussian model. A fully nonparametric approach, however, would involve high-dimensional kernels, which perform poorly due to the "curse of dimensionality." This disadvantage is especially noticeable for large-scale networks. For this reason, the principal investigator will introduce two dimension reduction mechanisms into the nonparametric approach: additive conditional independence and nonlinear sufficient dimension reduction. Additive conditional independence is a new statistical relation that resembles the Gaussian interaction structure without being restricted by the Gaussian (or copula Gaussian) distributional assumption. The graphical models based on additive conditional independence can capture intrinsically nonlinear interactions and at the same time avoid high-dimensional kernels. The second mechanism incorporates ideas and techniques from the most recent advances in nonlinear sufficient dimension in statistics and machine learning into the graphical models to reduce the dimension of the mapping kernels.</AbstractNarration>
    <MinAmdLetterDate>07/08/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>07/08/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1407537</AwardID>
    <Investigator>
      <FirstName>Bing</FirstName>
      <LastName>Li</LastName>
      <EmailAddress>bing@stat.psu.edu</EmailAddress>
      <StartDate>07/08/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Pennsylvania State Univ University Park</Name>
      <CityName>UNIVERSITY PARK</CityName>
      <ZipCode>168027000</ZipCode>
      <PhoneNumber>8148651372</PhoneNumber>
      <StreetAddress>110 Technology Center Building</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1269</Code>
      <Text>STATISTICS</Text>
    </ProgramElement>
  </Award>
</rootTag>
