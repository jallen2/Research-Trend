<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CCF: Capturing and Animating the Human Hand: Robust Recovery of Hand-Object Interactions</AwardTitle>
    <AwardEffectiveDate>06/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2011</AwardExpirationDate>
    <AwardAmount>325000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Lawrence Rosenblum</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>CCF: Capturing and Animating the Human Hand: Robust Recovery of Hand-Object Interactions&lt;br/&gt;&lt;br/&gt;Nancy Pollard&lt;br/&gt;&lt;br/&gt;Abstract&lt;br/&gt;This research addresses the problem of accurately capturing motion of the human hand. Capturing human hand motion has proven exceptionally difficult for a variety of reasons, including the complexity of the joints in the hand, variation in hand anatomy from person to person, small ranges of motion, difficulties related to motion capture technology, and complex contact conditions while manipulating objects. However, the hand is critically important for communication, caring for others and ourselves, and using tools to alter the world around us. This research covers a suite of practical techniques needed to make accurate, subject-specific capture of the human hand possible using today's hardware. These techniques, along with the corresponding hand motion database, will make it possible to study the workings of the hand when performing all manner of tasks with captured data at a high level of detail and accuracy. This work should be useful in rehabilitation for measuring progress in improving range of motion and in accomplishing everyday activities. It should be useful for exploring potential designs for robot hands. And it should also be of great use for exploring the basis of dexterity itself.&lt;br/&gt;&lt;br/&gt;This research involves three specific subtopics. The first is robust algorithms for automatic extraction of subject specific skeletal models from motion capture data. We then observe that marker protocol affects the results a great deal. Thus, the second subtopic of this research is obtaining well founded recommendations for marker protocols for accurate data capture. Next we observe that cleaned motion capture data does not capture the contact conditions that are so important to understanding grasping. Thus, the third subtopic of this research is developing optimization algorithms to obtain physically plausible representations of observed motion, even in situations with complex, changing contacts between deformable tissues of the hand and a manipulated object.</AbstractNarration>
    <MinAmdLetterDate>06/01/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>06/25/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0702443</AwardID>
    <Investigator>
      <FirstName>Nancy</FirstName>
      <LastName>Pollard</LastName>
      <EmailAddress>nsp@cs.cmu.edu</EmailAddress>
      <StartDate>06/01/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
  </Award>
</rootTag>
