<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RUI: Visual Navigation from Circular Feature Sequences</AwardTitle>
    <AwardEffectiveDate>08/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>320000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Abstract&lt;br/&gt;Proposal 0713442 &lt;br/&gt;PIs: Amy Briggs and Daniel Scharstein&lt;br/&gt;Institution: Middlebury College&lt;br/&gt;&lt;br/&gt;Title: RUI: Visual Navigation from Circular Feature Sequences&lt;br/&gt;&lt;br/&gt;Navigating the world from visual input alone is still one of the greatest challenges for mobile robots. Vision provides the richest but also most difficult input, since unambiguous and stable features that can serve as landmarks for navigation are hard to obtain. &lt;br/&gt;Challenges include the rich geometry of the world, changing scenes and obstacles, occlusion, lighting changes, specular and transparent surfaces, to name a few. Maintaining an accurate 3D model of world features and using them for localization and navigation is difficult due to the sheer amount of data to be processed.&lt;br/&gt;&lt;br/&gt;To face these challenges, this project presents a framework for navigation from one-dimensional circular feature sequences extracted from 2D panoramic images. Since many real-world navigation tasks of mobile entities are in the plane (e.g., walking in a single building floor, driving in the city), the goal is to identify a reduced feature set sufficient for navigation that uses little storage space and can be processed quickly.&lt;br/&gt;&lt;br/&gt;The key motivation for this work is to develop a simplified visual feature model that allows robust navigation in the plane but avoids most of the difficulties associated with extracting, modeling, and matching true 3D features and solving the associated six degree-of- freedom structure-from-motion problem. This work advances the state of the art in vision-based navigation on several fronts, with novel contributions in both robotics and computer vision. Specific algorithmic contributions include new feature descriptors invariant to planar motion, fast circular feature matching algorithms that allow both unmatched features and ordering reversals, probabilistic topological motion planning methods that include explicit modeling of the reliability of feature detection and identification, and strategies for graph-based world modeling and selective feature storage.&lt;br/&gt;&lt;br/&gt;The proposed techniques have wide applicability, ranging from autonomous robot navigation in unknown environments to camera-based navigation aides for pedestrians, bicyclists, and cars. The project also provides an opportunity to expose undergraduates at a liberal- arts college to the world of research, experimentation, and discovery.&lt;br/&gt;&lt;br/&gt;Undergraduate students at Middlebury College - an undergraduate institution in rural Vermont - will be actively involved in all components of this research. The student researchers will also join the PIs in authoring papers and attending conferences. Other students will benefit from the research activities through the integration of current research topics into the curriculum and through use of the lab facilities enhanced by the project. Tight integration of research and education is a central career goal of the PIs. Based on experience gained in prior and current collaboration with undergraduates, robotics and computer vision research is ideally suited to excite and challenge students.&lt;br/&gt;&lt;br/&gt;Progress on this project will be regularly reported at http:// vision.middlebury.edu/navigation</AbstractNarration>
    <MinAmdLetterDate>08/06/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>06/03/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0713442</AwardID>
    <Investigator>
      <FirstName>Amy</FirstName>
      <LastName>Briggs</LastName>
      <EmailAddress>briggs@middlebury.edu</EmailAddress>
      <StartDate>08/06/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Daniel</FirstName>
      <LastName>Scharstein</LastName>
      <EmailAddress>schar@middlebury.edu</EmailAddress>
      <StartDate>08/06/2007</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Middlebury College</Name>
      <CityName>MIDDLEBURY</CityName>
      <ZipCode>057536000</ZipCode>
      <PhoneNumber>8024435000</PhoneNumber>
      <StreetAddress>14 OLD CHAPEL ROAD</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Vermont</StateName>
      <StateCode>VT</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9216</Code>
      <Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
