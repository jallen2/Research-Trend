<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Parameter-Sensitive and Dynamics-Aware Methods for Object Detection, Pose Estimation, and Tracking</AwardTitle>
    <AwardEffectiveDate>08/15/2007</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2011</AwardExpirationDate>
    <AwardAmount>403816</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Parameter-Sensitive and Dynamics-Aware Methods for Object Detection, Pose Estimation, and Tracking&lt;br/&gt;&lt;br/&gt;The main goal of the proposed effort is to develop algorithms for simultaneous detection, parameter estimation, tracking, and classification of objects that exhibit high variability. While the aim is to develop a general framework time-varying objects, particular emphasis will be placed on modeling of articulated objects, like the human hand and human body. This research will focus on: (1) methods for dimensionality reduction that incorporate knowledge of object dynamics, (2) models that combine a collection of simpler local models to efficiently and accurately approximate nonlinear motion dynamics in a state-based model for tracking,&lt;br/&gt;(3) algorithms that can detect an instance of the object class in the image, and at the same time estimate the object's parameters.&lt;br/&gt;&lt;br/&gt;The resulting algorithms will be deployed in a prototype system that will support detection, parameter estimation, tracking and motion classification for video sequences of human motion. The methods will be tested with various motion capture and real-world video datasets of human motion: &lt;br/&gt;full&lt;br/&gt;body motion and gait, surveillance video, gestural communication, sports video, etc. Synthetic sequences, generated via computer graphics rendering from motion capture data, will be used in quantitative experiments where ground truth is required.&lt;br/&gt;&lt;br/&gt;The methods developed in this project would enable numerous applications that are valuable to society, for instance: homeland security; video- based analysis of human biomechanics for occupational safety, as well as dance and sports training; archive management and analysis for news, entertainment, and sports video; and non-intrusive monitoring of the motion patterns of handicapped, infirm, or elderly people to detect decline, danger, or to alert caregivers when needed.&lt;br/&gt;&lt;br/&gt;Keywords: Computer vision; object detection; articulated tracking; human motion analysis&lt;br/&gt;&lt;br/&gt;URL: http://www.cs.bu.edu/groups/ivc/ParameterSensitive/</AbstractNarration>
    <MinAmdLetterDate>08/09/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>03/24/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0713168</AwardID>
    <Investigator>
      <FirstName>Stan</FirstName>
      <LastName>Sclaroff</LastName>
      <EmailAddress>sclaroff@cs.bu.edu</EmailAddress>
      <StartDate>08/09/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Trustees of Boston University</Name>
      <CityName>BOSTON</CityName>
      <ZipCode>022151300</ZipCode>
      <PhoneNumber>6173534365</PhoneNumber>
      <StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
  </Award>
</rootTag>
