<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Parametric Compiler Optimization for Multi-Core Architectures</AwardTitle>
    <AwardEffectiveDate>08/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>275000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Almadena Y. Chtchelkanova</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The power dissipation problem is causing a shift of commodity microprocessor architectures towards multi-core chips. By industry's forecast, the number of cores, also known as computation engines, on a single chip is to increase at an exponential rate at least for the decade ahead of us. How to use multiple processors simultaneously for a single application problem is no longer an issue unique to the supercomputing domain but also to software that runs on commodity microprocessors. This project investigates the execution model, task scheduling methods and compiler techniques to achieve the goal of efficient use of multiple processors on a single chip.&lt;br/&gt;&lt;br/&gt;The focus of this project concerns the mapping between program operations and the complex architectures which offer parallelism and data locality in various forms on a single chip. Such intricate parallelism and localities make optimal deployment of computational tasks difficult for programmers to manage without associated compiler support and related programming tools. A critical research objective of this proposal is to design and implement a parametric approach to parallel code generation and scheduling on multi-core architectures. Based on this approach, an adaptive scheme for computation offloading is employed on heterogeneous multi-core (HMC) chips. The scheme is novel in two major aspects. Firstly, it has a single unified framework for several different system architectures of HMC, abstracting various architecture differences by a set of parameters plugged into a task partitioning mathematical system. Secondly, the code it generates, as the result of task partitioning, has the ability to adapt to the change in the program's execution context, including the data sizes and the execution options, which is often unpredictable at compile time.</AbstractNarration>
    <MinAmdLetterDate>06/29/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>08/18/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0702245</AwardID>
    <Investigator>
      <FirstName>Zhiyuan</FirstName>
      <LastName>Li</LastName>
      <EmailAddress>li@cs.purdue.edu</EmailAddress>
      <StartDate>06/29/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Purdue University</Name>
      <CityName>West Lafayette</CityName>
      <ZipCode>479072114</ZipCode>
      <PhoneNumber>7654941055</PhoneNumber>
      <StreetAddress>Young Hall</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Indiana</StateName>
      <StateCode>IN</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
  </Award>
</rootTag>
