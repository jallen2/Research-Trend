<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Evaluating student learning in geoscience curricula that employ conceptests using electronic student response systems</AwardTitle>
    <AwardEffectiveDate>08/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>37563</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11040200</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Undergraduate Education</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Peter Lea</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Geology (42)&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;We are exploring the impact of using electronic student response systems to facilitate learning in large introductory geoscience courses across the country. Students are provided a personally registered remote control that is used to answer conceptual questions during the actual class. The questions are text-, diagram- or graph-based multiple choice questions that focus on one key concept. They are intended to reinforce material presented in class. They provide immediate feedback to students as class responses are collected in near-real time and displayed on a graph at the front of the classroom. Students and instructors analyze the graphs, discuss the results and use that information to guide subsequent activities. Small group discussion of class responses is the primary mode of instruction. We are analyzing over 9000 student responses to identify questions that can be used as reliable in-class assessments at other institutions. Teaching and learning aids are also being developed to help students identify ways to better prepare for class so that they are successful in and out of class. We are varying the types of questions, amounts of response data students see and questioning techniques to determine which combinations provide the richest learning experiences. Data are being collected in six different states at community colleges, four-year colleges and research universities. The intellectual merit of this proposal includes analyses of data regarding the utility of using electronic response system and questions across populations, disciplines and educational settings and identification of better ways to ensure a scientifically literate population of non-science majors. The broader impact of this proposal includes the thorough study and documentation of student response to these questions by gender and ethnicity. Such documentation is leading to recommendations for how faculty can employ such assessments in the most inclusive way possible.</AbstractNarration>
    <MinAmdLetterDate>08/02/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>08/02/2007</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0716523</AwardID>
    <Investigator>
      <FirstName>Jake</FirstName>
      <LastName>Armour</LastName>
      <EmailAddress>jarmour@uncc.edu</EmailAddress>
      <StartDate>08/02/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of North Carolina at Charlotte</Name>
      <CityName>CHARLOTTE</CityName>
      <ZipCode>282230001</ZipCode>
      <PhoneNumber>7046871888</PhoneNumber>
      <StreetAddress>9201 University City Boulevard</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>North Carolina</StateName>
      <StateCode>NC</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
  </Award>
</rootTag>
