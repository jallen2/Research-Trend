<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SGER - Vision and RFID for Multimodal Tracking of Working Teams</AwardTitle>
    <AwardEffectiveDate>09/15/2007</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2009</AwardExpirationDate>
    <AwardAmount>84967</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>David W. McDonald</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project proposes novel strategies for the automatic capture of teamwork in crowded spaces. The initial goal is to develop new methods for acquisition of people and artifact locations using diverse modalities, including machine vision and radiofrequency identification (RFID). Following, software will be developed in order to integrate these observations and track team members and artifacts over time. Ultimately probabilistic reasoning will be used to identify team tasks based on these unified observations. The representative domain of trauma resuscitation is an ideal environment for this work since the roles and tasks of players are well-defined and the flow of work follows a general schema regardless of the patient's injuries. The system will be tested in simulated trauma scenarios using a robotic mannequin patient. &lt;br/&gt;&lt;br/&gt;There are two key benefits of this work. First, the process of deriving system requirements for computerized teamwork support systems demands analyzing a large number of observations of current practices. Automatic transcription and tagging of teamwork will allow for efficient capture and interpretation of events and is preferable to more tedious and error-prone observations by experts. Second, automatic tracking of team activities is a needed initial step in the development of "smart rooms" that provide computerized support of teamwork. &lt;br/&gt;&lt;br/&gt;The core contribution of this project will be a proof-of-concept system integrating tracking of actors and medical objects using computer vision and RFID tracking. The proposed approach will develop novel algorithms and methods for (i) vision-based person tracking in crowded collaborative environments and (ii) fusion of unreliable data from multimodal sensors to achieve reliable recognition of human activities. &lt;br/&gt;&lt;br/&gt;Broader Impacts&lt;br/&gt;The scientific importance of this work is in the need to tag video observations. Many forms of videos are of repetitive behaviors, whether in surveillance applications, work situations, or other uses. In all such cases, applying a grammar to the video, and matching actions and sounds to that grammar, has the possibility of greatly simplifying the job of work analysis - a critical phase in the development process of computer support for complex, high-risk human activities. This work will also provide the foundation for implementing decision aids in environments such as trauma resuscitation and related medical domains that lack effective methods for instrument tracking of work.</AbstractNarration>
    <MinAmdLetterDate>09/12/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>06/12/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0749246</AwardID>
    <Investigator>
      <FirstName>Randall</FirstName>
      <LastName>Burd</LastName>
      <EmailAddress>rburd@cnmc.org</EmailAddress>
      <StartDate>09/12/2007</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Lesk</LastName>
      <EmailAddress>lesk@acm.org</EmailAddress>
      <StartDate>09/12/2007</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Ivan</FirstName>
      <LastName>Marsic</LastName>
      <EmailAddress>marsic@ece.rutgers.edu</EmailAddress>
      <StartDate>09/12/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Ahmed</FirstName>
      <LastName>Elgammal</LastName>
      <EmailAddress>elgammal@cs.rutgers.edu</EmailAddress>
      <StartDate>09/12/2007</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Rutgers University New Brunswick</Name>
      <CityName>Piscataway</CityName>
      <ZipCode>088543925</ZipCode>
      <PhoneNumber>8489320150</PhoneNumber>
      <StreetAddress>33 Knightsbridge Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9237</Code>
      <Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
