<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Multisensory Underpinnings of Lexical Comprehension</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2013</AwardExpirationDate>
    <AwardAmount>127757</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>David Moore</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Infants learn about words and the actions or objects to which the words refer in a multi-sensory world. Caregivers steer their infants into this multi-sensory world by highlighting word-object or -action relations. For example, during interactive play, mothers name objects and actions to their 5- to 8-month-olds by using spoken words and moving objects simultaneously. Infants of this age also show heightened perception of these simultaneous word-object presentations. They learn word-object relations best, in natural and laboratory settings, if the spoken words and object motions occur at the same time and in the same space. These findings suggest that infants' ability to put words and objects or actions together emerge from their auditory-visual perceptual abilities. At present, however, we do not know how infants transition developmentally from general auditory-visual perception to more language specific abilities. We do not know for example, how infants might learn the relations between the word "woof-woof" and a dog, and later, the word "dog" and the dog. In addition, we know little about the optimal temporal or spatial window within which words and objects or actions must occur for young infants to learn their relations, or how these timing and spatial windows might change with development from 6- to 9 months. Neither do we know how infants' perceptual learning of word-object or action relations in the laboratory is related to their vocabulary development in natural settings. The proposed experiments address these questions concerning the origins of word comprehension in humans, and provide an unprecedented opportunity to bridge an existing gap in the infant language development, perception and cognition literature. The findings are of direct relevance to developmental psychology. They promise to link the early auditory-visual perceptual abilities of infants prior to 6 months to the early word learning and referential abilities seen in older infants at the end of the first year and beyond. Further, this research will use multiple methods for examining this link. It will combine traditional methods such as infant-controlled habituation and standardized language assessment, with a relatively novel technique such as eye-tracking to examine group and individual differences in infant word learning. &lt;br/&gt;&lt;br/&gt;The knowledge gained from the present research, on best practice during naming, will be useful to parents, and to clinicians and educators who work with infants and young children. This knowledge could inform early intervention practices for infants with sensory and language delays. As a case in point, knowledge of the time and space windows within which typically developing infants learn to put words and objects together, and the relation of this learning in the lab to infants' language in natural setting will inform clinicians and educators about how infants typically learn. This information can be compared with the time and space windows for word learning in at-risk populations, to diagnose and provide interventions in cases with vocabulary delays. Furthermore, the geographical location of the present project will enable the study of minority groups that are generally under-represented in infancy research. In addition, this research project will provide an excellent training opportunity for undergraduate students, and a post doc to participate in all its facets, paving their way to become future scientists. In the future, it will foster cross-disciplinary research in the fields of computer science and psychology. For example, the eye-tracker measures gathered will be used for the future design of sensory-oriented computational models of word learning and language development. Such models will, in turn, make predictions for future infant word learning experiments and further our understanding of the developmental process in humans.</AbstractNarration>
    <MinAmdLetterDate>08/30/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>06/13/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1123890</AwardID>
    <Investigator>
      <FirstName>Lakshmi</FirstName>
      <LastName>Gogate</LastName>
      <EmailAddress>lgogate@fgcu.edu</EmailAddress>
      <StartDate>08/30/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Florida Gulf Coast University</Name>
      <CityName>Fort MYERS</CityName>
      <ZipCode>339656565</ZipCode>
      <PhoneNumber>2395907022</PhoneNumber>
      <StreetAddress>10501 FGCU Blvd. South</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Florida</StateName>
      <StateCode>FL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1698</Code>
      <Text>DS - Developmental Sciences</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>1698</Code>
      <Text>DEVELOP&amp; LEARNING SCIENCES/CRI</Text>
    </ProgramReference>
  </Award>
</rootTag>
