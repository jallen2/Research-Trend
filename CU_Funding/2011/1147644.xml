<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Joint Learning for Knowledge-Rich Coreference Resolution</AwardTitle>
    <AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2014</AwardExpirationDate>
    <AwardAmount>130004</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Early Grant for Exploratory Research seeks to investigate the viability of a knowledge-rich, joint-learning approach to coreference resolution, with the ultimate goal of advancing the state of the art in coreference resolution. Given recent advances in research on lexical semantics and discourse, and the development of large-scale lexical databases, the first objective of this grant is to investigate whether existing language technologies are mature enough to accurately extract semantic, discourse, and world knowledge from structured and unstructured data so that learning-based coreference systems can be significantly improved when such knowledge is employed.&lt;br/&gt;&lt;br/&gt;An assumption underlying the first objective is the use of a pipeline system architecture, where sophisticated linguistic information from various sources is computed prior to coreference resolution. While a pipeline architecture is popularly-used in coreference research, the errors made by the upstream components may propagate to the coreference component and adversely affect its performance. To address this problem, the second objective of this grant is to explore an approach in which multiple tasks in the pipeline are learned in a joint fashion. While most research on joint learning for language processing focuses on two tasks, this work seeks to take the challenge involved in joint learning to the next level by simultaneously learning a large number of tasks in semantics, discourse, and information extraction, which can all benefit from their interactions with each other and with coreference in the learning process.</AbstractNarration>
    <MinAmdLetterDate>07/26/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>07/26/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1147644</AwardID>
    <Investigator>
      <FirstName>Vincent</FirstName>
      <LastName>Ng</LastName>
      <EmailAddress>vince@hlt.utdallas.edu</EmailAddress>
      <StartDate>07/26/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Dallas</Name>
      <CityName>Richardson</CityName>
      <ZipCode>750803021</ZipCode>
      <PhoneNumber>9728832313</PhoneNumber>
      <StreetAddress>800 W. Campbell Rd., AD15</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
