<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CIF: Small: Fast Stagewise Learning of Sparse Hierarchical Data Representations</AwardTitle>
    <AwardEffectiveDate>07/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2015</AwardExpirationDate>
    <AwardAmount>372000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Increasingly, real-world data has many dimensions or features but rather than filling out all dimensions equally, the data distributed on or near a surface of much lower intrinsic dimension. Examples include fMRI data and natural image and video data sets. This research will push the boundary of what is currently possible in the analysis of such large data sets by incorporating hierarchical structure into what is known as a "sparse dictionary representation" of the data. The results will include both basic intellectual contributions to machine learning methods and computational advancements that will aid the investigation of complex real world data. &lt;br/&gt;&lt;br/&gt;A fundamental problem in learning the structure of complex data is how to effectively extract a set of features that reflects the underlying structure of the data. In many applications, including face recognition and object recognition, sparse dictionary representations have proved effective for this purpose. However, since solving large-scale sparse representation problems is very expensive, the method is generally limited to problems of moderate scale. This research reformulates the method into an incremental, multi-stage, hierarchical dictionary learning process. This approach incrementally extracts information from the data and uses this to refine the data representation in an organized hierarchical fashion. This enables the building of large-scale dictionaries in a computationally efficient way. The method hence extends the power of sparse dictionary representation methods to a wider variety of real world applications. It also has the flexibility to incorporate an existing state-of-the-art sparse coding algorithm as the basic solver and hence can extend the functionality of existing sparse coding algorithms to multi-stage, hierarchical dictionary learning.</AbstractNarration>
    <MinAmdLetterDate>06/30/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>06/30/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1116208</AwardID>
    <Investigator>
      <FirstName>Peter</FirstName>
      <LastName>Ramadge</LastName>
      <EmailAddress>ramadge@princeton.edu</EmailAddress>
      <StartDate>06/30/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Princeton University</Name>
      <CityName>Princeton</CityName>
      <ZipCode>085442020</ZipCode>
      <PhoneNumber>6092583090</PhoneNumber>
      <StreetAddress>Off. of Research &amp; Proj. Admin.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New Jersey</StateName>
      <StateCode>NJ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7797</Code>
      <Text>COMM &amp; INFORMATION FOUNDATIONS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7936</Code>
      <Text>SIGNAL PROCESSING</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
