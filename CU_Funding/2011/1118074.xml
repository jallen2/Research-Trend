<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>HCC: Small: Proprioceptive Displays to Engage Blind Users into Healthy Whole Body Interaction</AwardTitle>
    <AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2015</AwardExpirationDate>
    <AwardAmount>410220</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Lack of physical activity is a serious health concern for individuals with visual impairments. In particular, children with visual impairments have limited access to physical education, recreation, and athletic programs for a variety of reasons including fear of injury, safety concerns of parents and teachers, and lack of sighted guides with whom to exercise. The PI's hypothesis is that video games, which have been identified as a contributing factor to the increasingly sedentary behavior of children in general and associated higher levels of obesity, may provide a solution. A new genre of "exergames" use upper and/or lower-body gestures (such as steps, punches, and kicks directed at virtual targets), to provide players with an immersive experience that engages them in moderate-to-vigorous physical activity that is high enough to yield health benefits. The PI's goal in this project is to investigate how proprioceptive displays can be designed and built to facilitate exercise games for blind adolescents. Proprioception, the ability to sense the position and orientation of one's body and its parts, is an interoceptive sensory modality distinct from exteroceptive sensory modalities such as sight, touch, and hearing, and has remained largely unexplored as a modality of feedback. In performing a gesture we generally combine visual and proprioceptive information, but once the location of a target has been memorized proprioceptive feedback alone is sufficient for relating the position of the user's limb to the target. Since the location of a target primarily is acquired visually, gestures are difficult to perform for users with visual impairments. This project will test the hypothesis that whole body gestures can be performed by blind users in exergames when target direction is acquired using a proprioceptive display.&lt;br/&gt;&lt;br/&gt;In prior work, the PI has explored single proprioceptive displays for acquiring the direction to a target in a horizontal plane by having users scan a horizontal line with a hand-held orientation aware device; a vibrotactile cue was used to indicate when the device was pointed at the target, with target direction conveyed to the user using proprioception. Preliminary results have demonstrated that blind users can perform an upper body gesture aimed at a target in a plane where direction to the target is acquired using a proprioceptive display. This project will significantly advance our understanding of proprioceptive displays by: (1) quantifying spatial and temporal resolutions of discrete proprioceptive displays; (2) developing efficient scanning strategies for conveying points in a plane (directions to points in a space) using an analog proprioceptive display and determining the effectiveness of using multiple proprioceptive displays; (3) investigating the efficacy with which whole-body directed gestures can be performed using proprioceptive displays; and (4) establishing whether rhythmic sequences of whole-body directed gestures performed using a proprioceptive display can be memorized using audio cues. Through generation of empirical data with exergames that involve whole-body gestures, this project will develop a fundamental and transformative understanding of proprioceptive displays in order to articulate a set of principles for their design. &lt;br/&gt;&lt;br/&gt;Broader Impacts: Children with visual impairments have significantly higher levels of obesity and often exhibit delays in motor development caused by a general lack of opportunities to be physically active. Through development of open-source exergames that can be played using commercial off-the-shelf controller technology without the aid of a sighted guide and with minimal risk of injury, this project will increase existing exercise and socialization opportunities for members of this vulnerable population. More generally, because proprioceptive displays can be implemented using low cost technology that is often already present in mobile devices, these displays may ultimately facilitate the development of robust ear- and eye-free forms of interaction for everyone (e.g., for motor rehabilitation or sports training). This research will directly involve both graduate and undergraduate students, and the PI will use this work as the basis for compelling design projects in his courses. The PI will also develop outreach efforts such as summer camps for K-12 students with visual impairments (and other minorities) in order to attract them to computer science and STEM.</AbstractNarration>
    <MinAmdLetterDate>08/12/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/25/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1118074</AwardID>
    <Investigator>
      <FirstName>Eelke</FirstName>
      <LastName>Folmer</LastName>
      <EmailAddress>efolmer@unr.edu</EmailAddress>
      <StartDate>08/12/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Board of Regents, NSHE, obo University of Nevada, Reno</Name>
      <CityName>Reno</CityName>
      <ZipCode>895570001</ZipCode>
      <PhoneNumber>7757844040</PhoneNumber>
      <StreetAddress>1664 North Virginia Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Nevada</StateName>
      <StateCode>NV</StateCode>
    </Institution>
  </Award>
</rootTag>
