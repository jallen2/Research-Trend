<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CSR:Small:Parallelism and Concurrency in Scripting Languages</AwardTitle>
    <AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2014</AwardExpirationDate>
    <AwardAmount>250000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Anita J. LaSalle</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The past decade has seen an explosion of interest in so-called "dynamic" or "scripting" programming languages, which emphasize programmer productivity at the possible expense of run-time performance. Among other applications, scripting languages are central to much web-based and mobile computing. With increasing use, and with the proliferation of multicore processors, there will be inevitable pressure to improve the performance of these languages through parallel execution. Unfortunately, the state of the art in parallel scripting has not kept pace with parallel architecture developments. While many scripting languages support asynchronous handling of events from the external world, programmer-centric features, like dynamic typing, make it very difficult for event handlers and the main program&lt;br/&gt;-- or multiple aspects of the main program -- to execute efficiently and simultaneously on separate cores of a modern processor.&lt;br/&gt;&lt;br/&gt;The goal of this project is to build a detailed understanding of the tradeoffs between scripting language design and the performance of parallel execution. This goal is accomplished through two main tasks: (1) minimizing the overhead necessary to safeguard the language implementation in the face of parallel execution, and (2) quantifying the marginal cost of different models of data sharing and memory consistency. The bulk of the work takes place in the Ruby scripting language, widely used for Internet server development. This approach will leverage recent developments in transactional memory, read-mostly synchronization, and high-performance data structures.&lt;br/&gt;&lt;br/&gt;This project will contribute directly to the training of students at both the graduate and undergraduate level, and to curricula for courses at both the advanced and introductory level. More broadly, effective support for parallelism in mainstream scripting languages can be expected to produce significant improvements in productivity across the full range of computer applications, in government, industry, science, the arts, and entertainment.</AbstractNarration>
    <MinAmdLetterDate>08/08/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>08/08/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1116109</AwardID>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Scott</LastName>
      <EmailAddress>scott@cs.rochester.edu</EmailAddress>
      <StartDate>08/08/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Rochester</Name>
      <CityName>Rochester</CityName>
      <ZipCode>146270140</ZipCode>
      <PhoneNumber>5852754031</PhoneNumber>
      <StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7354</Code>
      <Text>COMPUTER SYSTEMS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7354</Code>
      <Text>COMPUTER SYSTEMS</Text>
    </ProgramReference>
  </Award>
</rootTag>
