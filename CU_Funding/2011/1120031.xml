<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Multimodal Communication, mate choice and predation risk</AwardTitle>
    <AwardEffectiveDate>08/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2017</AwardExpirationDate>
    <AwardAmount>779266</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>08090500</Code>
      <Directorate>
        <LongName>Direct For Biological Sciences</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Integrative Organismal Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Emilia Martins</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>We receive and analyze information from our environment through multiple senses (i.e. sensory channels). When we interact socially, for example, we not only listen to someone?s words but we also read their body language to interpret their meaning. But how does information from different sensory channels interact to influence our social decisions? In this series of studies how acoustic and visual cues influence mate choice decisions will be determined in the túngara frog. As do most frogs, túngara frogs advertise for mates with loud and conspicuous mating calls. Females compare mating calls among males and use this information to choose a mate. But the female?s decision is also influenced by the presence of a visual cue, the male?s large and conspicuous vocal sac. Using robotic frogs it has been shown that females prefer a calling male with a large inflating-deflating vocal sac to a male producing the same call but without a dynamic vocal sac. To build upon those results to address several fundamental questions about how acoustic and visual cues interact to influence female decision making the following will be determined: What is the relative value of acoustic and visual cues? Does the addition of visual cues influence a female?s memory of calls? Do visual cues aid in recognizing individual males in large choruses? Does the addition of a visual cue influence the time it takes for females to make decisions? All of these studies will provide insights into how animals, including humans, integrate information in the environment around them through different sensory channels. In the process of this work, approximately 25 students, many of them women and minorities, will be trained in the use of robotic technologies to study behavior.</AbstractNarration>
    <MinAmdLetterDate>08/22/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>06/07/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1120031</AwardID>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Ryan</LastName>
      <EmailAddress>mryan@utexas.edu</EmailAddress>
      <StartDate>08/22/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7659</Code>
      <Text>ANIMAL BEHAVIOR</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1228</Code>
      <Text>MINORITY INVOLVEMENT -- BIO</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9178</Code>
      <Text>UNDERGRADUATE EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9179</Code>
      <Text>GRADUATE INVOLVEMENT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7659</Code>
      <Text>ANIMAL BEHAVIOR</Text>
    </ProgramReference>
  </Award>
</rootTag>
