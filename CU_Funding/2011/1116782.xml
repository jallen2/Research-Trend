<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: A Bayesian Approach to Dynamic Lexical Resources for Flexible Language Processing</AwardTitle>
    <AwardEffectiveDate>09/01/2011</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2015</AwardExpirationDate>
    <AwardAmount>300000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project uses statistical models and human judgment to determine dynamic, probabilistic representations of extensible usages of words; these representations are suitable for incorporation into VerbNet, a lexical resource widely used in the Natural Language Processing (NLP) community. Existing lexical resources reflect a binary notion of usages as grammatical or not. However, in actual language use, forms vary in acceptability; moreover, the process of coercion extends words beyond their standard usages. For example, a strictly intransitive action verb such as 'sneeze' may be used as in 'She sneezed the foam off the cappuccino', expressing manner of motion. This research has a two-pronged approach involving extensive use of machine learning and a fundamental shift in the development and use of VerbNet. Specifically, the research develops probabilistic methods for: (1) analyzing usages of verbs in large corpora and incorporating the resulting probabilistic information into VerbNet classes; and (2) representing information about the likelihood of potential constructional coercions and the productivity of such extensions. These developments use the Hierarchical Bayesian Model of Parisien and Stevenson, which are an ideal framework for marrying probabilistic reasoning about complex, real-world data within the hierarchically-organized VerbNet lexicon. In addition to statistical models, the representations are also informed by human judgments with respect to the use of such constructions. Thus, this research enriches the current symbolic verb representations in VerbNet with probabilistic distributional information, which becomes salient through the influence of construction grammar. &lt;br/&gt;&lt;br/&gt;Encoding verb knowledge probabilistically provides the necessary flexibility to represent extensional constructions and support their appropriate interpretation by NLP systems. This is especially useful for interpretation in new domains and genres, leading to advances in NLP technologies, such as question answering and machine translation, thus improving information access. Additionally, insights into statistical properties of constructions gained through this research are valuable for psycholinguistic models of language acquisition and second language learning.</AbstractNarration>
    <MinAmdLetterDate>08/05/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>07/28/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1116782</AwardID>
    <Investigator>
      <FirstName>Martha</FirstName>
      <LastName>Palmer</LastName>
      <EmailAddress>mpalmer@colorado.edu</EmailAddress>
      <StartDate>08/05/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Colorado at Boulder</Name>
      <CityName>Boulder</CityName>
      <ZipCode>803031058</ZipCode>
      <PhoneNumber>3034926221</PhoneNumber>
      <StreetAddress>3100 Marine Street, Room 481</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Colorado</StateName>
      <StateCode>CO</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
