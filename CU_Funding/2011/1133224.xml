<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Underwater Optical Communication and Perception</AwardTitle>
    <AwardEffectiveDate>07/15/2011</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2014</AwardExpirationDate>
    <AwardAmount>49999</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gregory Chirikjian</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The project develops a high data rate optical communication system and a localization algorithm that combines optical with acoustic information as well as two robot capabilities that use the optical communication system. The first explores new methods for acoustic and optical underwater coordination that lead to target identification and efficient data muling using autonomous underwater vehicles. The second explores the use of optical communication as a remote control of an underwater robot as well as for live video transmission from the robot.&lt;br/&gt;&lt;br/&gt;The systems contribute a new approach to search and rescue at sea and also enhance the tools available to marine sciences. The proposed underwater systems enhance the scope of observations and communication of the ocean?s physical properties which are essential for advancing knowledge on a wide variety of multi-disciplinary, societally-relevant concerns such as climate variability, gaseous sequestration (e.g., CO2), biogeochemical cycles, and ecosystem dynamics for small scale (e.g., phytoplankton) to large scale (e.g., mammals and commercial fisheries) biota. Furthermore, there is an international collaboration with Prof Hirose from the Tokyo Institute of Technology (TIT) to create an optically-enabled version of AnchorDiver III and demonstrate its ability to localize, communicate, and transmit video imaging. This involves student and faculty exchanges in the international research community.</AbstractNarration>
    <MinAmdLetterDate>07/15/2011</MinAmdLetterDate>
    <MaxAmdLetterDate>07/15/2011</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1133224</AwardID>
    <Investigator>
      <FirstName>Daniela</FirstName>
      <LastName>Rus</LastName>
      <EmailAddress>rus@csail.mit.edu</EmailAddress>
      <StartDate>07/15/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Massachusetts Institute of Technology</Name>
      <CityName>Cambridge</CityName>
      <ZipCode>021394301</ZipCode>
      <PhoneNumber>6172531000</PhoneNumber>
      <StreetAddress>77 MASSACHUSETTS AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
