<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>BIGDATA: Small: DCM: Data Management for Analytics Applications on Modern Architecture</AwardTitle>
    <AwardEffectiveDate>06/01/2013</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2017</AwardExpirationDate>
    <AwardAmount>680916</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Sylvia J. Spengler</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>We are now in the midst of the big data revolution where enterprise services are increasingly being driven by operational and business models that are powered by data analysis. A key part in making big data successful is ensuring that basic data processing primitives can execute efficiently on large and every increasing volumes of data. However, data processing kernels today largely employ techniques that have been designed about three decades ago, and are now out of touch with modern hardware that has made a fundamental technological shift. First, driven by power consumption characteristics, modern processors now have multiple processing units (called cores) fabricated in a single chip. In contrast, processors just a few years ago were single core. Second, traditionally the storage media for data has been the magnetic hard disk. Now, data has started to move nearly permanently to higher levels of the memory hierarchy, and more specifically to main memory. The goal of this project is to rethink key aspects of data processing techniques for the modern many-core and main memory hardware environment. The research approach is to design, implement and evaluate various methods for data kernels that can be used to store and process data efficiently. In other words, the key focus is on producing data kernels that "run at the speed of modern hardware." Thus, this project aims to have a broad impact on the big data ecosystem by developing faster, cheaper and more energy-efficient data kernels.</AbstractNarration>
    <MinAmdLetterDate>06/11/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>06/11/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1250886</AwardID>
    <Investigator>
      <FirstName>Jignesh</FirstName>
      <LastName>Patel</LastName>
      <EmailAddress>jignesh@cs.wisc.edu</EmailAddress>
      <StartDate>06/11/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Wisconsin-Madison</Name>
      <CityName>MADISON</CityName>
      <ZipCode>537151218</ZipCode>
      <PhoneNumber>6082623822</PhoneNumber>
      <StreetAddress>21 North Park Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Wisconsin</StateName>
      <StateCode>WI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8083</Code>
      <Text>Big Data Science &amp;Engineering</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7433</Code>
      <Text>CyberInfra Frmwrk 21st (CIF21)</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8083</Code>
      <Text>Big Data Science &amp;Engineering</Text>
    </ProgramReference>
  </Award>
</rootTag>
