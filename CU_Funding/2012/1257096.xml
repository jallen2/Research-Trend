<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Disparity and Correspondence in Human Stereo Vision</AwardTitle>
    <AwardEffectiveDate>03/01/2013</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2017</AwardExpirationDate>
    <AwardAmount>435907</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Catherine Arrington</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Due to their different locations, our left and right eyes have slightly different views of the world. It has been known since the 1830's that a horizontal disparity (shift) between the position of an image on the retinas of the left and right eyes is sufficient for humans to see that image in depth. Combining the two retinal images allows us to see stereoscopically the full three-dimensional volume of scenes (and even some movies and comic books). Stereoscopic vision helps people to navigate, to locate, identify and grasp objects, to judge distances, and to drive vehicles. The goal of this research project is to understand how the brain interprets retinal disparities as cues to stereoscopic depth. Horizontal disparities are relative easy to interpret; this is because of the separation of the eyes, when we are in upright posture, is horizontal. However, in naturalistic scenes disparities can have any direction, not just horizontal, and interpreting them is complicated by the variety of spatial arrangements among objects can influence the disparity directions we encounter. Therefore, understanding how humans see depth requires that we understand how the brain analyzes this two-dimensional (horizontal and vertical) disparity signal. The investigator will measure the depth that people perceive as they view displays containing several patterns, each with its own disparity direction. &lt;br/&gt;&lt;br/&gt;The knowledge gained from these studies will help scientists understand how humans and other animals combine images from the two eyes in order to recover information not available from either eye alone and how perception of 3-D space can be distorted when this information is combined incorrectly. Learning about the brain's strategies in achieving normal 3-D vision will help explain why visual areas of the brain are organized the way they are and aid in the design of treatments for impaired stereoscopic vision (from, for example, amblyopia and strabismus, or "lazy eye"). It will also help in the design of more effective artificial depth-sensing systems and improve machine-vision algorithms for object recognition, robotics, and visual prosthetic devices.</AbstractNarration>
    <MinAmdLetterDate>02/12/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>08/08/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1257096</AwardID>
    <Investigator>
      <FirstName>Bart</FirstName>
      <LastName>Farell</LastName>
      <EmailAddress>bfarell@syr.edu</EmailAddress>
      <StartDate>02/12/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Syracuse University</Name>
      <CityName>SYRACUSE</CityName>
      <ZipCode>132441200</ZipCode>
      <PhoneNumber>3154432807</PhoneNumber>
      <StreetAddress>OFFICE OF SPONSORED PROGRAMS</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7252</Code>
      <Text>Perception, Action and Cognition</Text>
    </ProgramReference>
  </Award>
</rootTag>
