<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>A Lightweight Event-Based Synthetic Vision System for Assisted-Living and Machine Vision Applications</AwardTitle>
    <AwardEffectiveDate>08/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>330000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07010000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Electrical, Commun &amp; Cyber Sys</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Hao Ling</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).&lt;br/&gt;&lt;br/&gt;The objective of this research is to enable highly mobile computers and cellular phones with the image interpretation capabilities of large bench-top computers. The approach combines new event-based hardware and energy-efficient algorithms for the identification of objects in an image stream. The algorithmic core of this research is a lightweight implementation of a biologically-plausible engine for size and position independent object recognition in images. The use of event-based sensors and processing hardware has the potential to increase computational throughput and synthetic vision efficiency.&lt;br/&gt;&lt;br/&gt;With respect to intellectual merit, the proposed research is intended to give event-based imaging devices the ability to extract specific information from visual streams. The size- and position-independent algorithms implemented in hardware are an enabling technology for efficient object recognition, and are necessary for the advancement of event-based artificial vision platforms. The research targets the design of event-driven processing hardware to extract object features with lightweight digital circuitry and utilizes spatial and temporal redundancy to increase the identification reliability.&lt;br/&gt;&lt;br/&gt;With respect to potential broader impacts, this research has the potential to allow a cellular phone to serve as a virtual cane for the blind, help assisted-living patients, provide environmental awareness, and extend human senses. More broadly, this research can be applied to artificial vision, robot vision, image sensor networks, assisted-living systems, and monitoring systems. The project leverages the biomimetic nature of the approach to train students, particularly women and students from other underrepresented groups and to motivate them to pursue careers in research and academia through seminars, classes, and projects.</AbstractNarration>
    <MinAmdLetterDate>06/29/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>09/02/2011</MaxAmdLetterDate>
    <ARRAAmount>330000</ARRAAmount>
    <AwardID>0901742</AwardID>
    <Investigator>
      <FirstName>Andreas</FirstName>
      <LastName>Savvides</LastName>
      <EmailAddress>andreas.savvides@yale.edu</EmailAddress>
      <StartDate>09/02/2011</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Eugenio</FirstName>
      <LastName>Culurciello</LastName>
      <EmailAddress>euge@purdue.edu</EmailAddress>
      <StartDate>06/29/2009</StartDate>
      <EndDate>09/02/2011</EndDate>
      <RoleCode>Former Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Yale University</Name>
      <CityName>New Haven</CityName>
      <ZipCode>065208327</ZipCode>
      <PhoneNumber>2037854689</PhoneNumber>
      <StreetAddress>Office of Sponsored Projects</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Connecticut</StateName>
      <StateCode>CT</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0510403</Code>
      <Name>Engineering &amp; Computer Science</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7564</Code>
      <Text>COMMS, CIRCUITS &amp; SENS SYS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>6890</Code>
      <Text>RECOVERY ACT ACTION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7423</Code>
      <Text>Energy collection &amp; storage</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
