<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Efficient Stochastic Oracle Based Algorithms for Stochastic Programming and Large Scale Convex Optimization</AwardTitle>
    <AwardEffectiveDate>09/15/2009</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>327417</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Junping Wang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The proposed research is aimed at developing computational techniques for handling two classes of complex convex problems. The first is Stochastic Programming, where objective and the constraints are given implicitly, as expectations over stochastic uncertain data, and thus are difficult to compute.&lt;br/&gt;The second class is formed by large-scale well-structured deterministic convex programs like those of Linear or Semidefinite Programming, the difficulty coming from huge problem sizes; e.g., LP's with just few thousands of variables and constraints and dense constraint matrices (arising, e.g., in Compressed Sensing and Machine Learning), or typical Semidefinite programs of similar sizes, are often beyond the grasp of the state-of-the-art solvers. The proposed research is intended to treat both these problem classes simultaneously, reducing them to variational inequalities with monotone operators represented by unbiased easy-to-compute stochastic oracles. These oracles arise naturally in the context of Stochastic Programming and can be constructed (e.g., via randomizing matrix-vector multiplications) in the case of large-scale LP's and SDP's. In order to solve the resulting stochastic variational inequalities it is proposed to employ recently developed algorithms (Robust Mirror Descent Stochastic Approximation and Stochastic Mirror Prox) which, under favorable circumstances, exhibit nearly dimension-independent and theoretically unimprovable in the large scale case rate of convergence.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;The last two decades have witnessed dramatic progress in techniques for solving convex optimization problems -- progress which by some estimates led to 1.000.000-fold performance growth, the factor nearly equally contributed by advances in algorithms and by increase in hardware power.&lt;br/&gt; In spite of this progress, a significant gap between what is needed by applications and what can be routinely solved by the state-of-the-art convex programming algorithms still persists, especially when the problems to be processed are intrinsically difficult. The proposed research is aimed at bridging the above gap by developing novel, more powerful than the existing alternatives, computational techniques based on systematic replacement of difficult to compute in the large scale case quantities, like matrix-vector products involving huge matrices, with relatively easy to compute randomized estimates of these quantities. Coupled with carefully designed stochastic type algorithms, this allows to solve huge problems, unaccessible by currently available deterministic algorithms, in a reasonable time with a reasonable accuracy by observing only a small portion of the data. This can be of paramount importance, e.g., for various applications of machine learning techniques where the amount of available data by far too large for direct processing. &lt;br/&gt;Some preliminary theoretical and numerical results are very encouraging and suggest that the proposed avenue of research is&lt;br/&gt;highly promising, and if successful the proposed research will advance &lt;br/&gt;optimization theory and practice by enriching the algorithmic know-how&lt;br/&gt;related to processing complex optimization problems.</AbstractNarration>
    <MinAmdLetterDate>09/14/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>09/14/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0914785</AwardID>
    <Investigator>
      <FirstName>Alexander</FirstName>
      <LastName>Shapiro</LastName>
      <EmailAddress>ashapiro@isye.gatech.edu</EmailAddress>
      <StartDate>09/14/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Arkadi</FirstName>
      <LastName>Nemirovski</LastName>
      <EmailAddress>nemirovs@isye.gatech.edu</EmailAddress>
      <StartDate>09/14/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
  </Award>
</rootTag>
