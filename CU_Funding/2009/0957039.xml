<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>II-NEW: Towards an Infrastructure for Research on Multimodal Language Processing in Situated Human Robot Dialogue</AwardTitle>
    <AwardEffectiveDate>03/01/2010</AwardEffectiveDate>
    <AwardExpirationDate>02/28/2014</AwardExpirationDate>
    <AwardAmount>229275</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A new generation of robots is emerging which aims to interact with humans on a daily basis to provide service, care, and companionship. To support natural interaction between people and this type of robot, robust language processing enabling situated human robot dialogue will become increasingly important. Compared to traditional spoken dialogue systems and multimodal conversational interfaces, situated human robot dialogue is drastically different due to two unique characteristics. The first characteristic is situatedness. A robot is situated in a physical world that is cohabited with human partners. The spatial relations between the robot, the human, and the environment, and the dynamic nature of the surroundings, have a massive influence on how the robot accomplishes its task and interacts with the human. The second characteristic is embodiment. A robot and its human partner both have physical bodies in the environment. In embodied communication, speakers make extensive use of non-verbal modalities (e.g., eye gaze and gestures) to engage in conversation and make reference to the shared environment. These two characteristics make automated interpretation of human language in situated human robot dialogue extremely challenging. This is funding to provide the PI and her team with an enhanced infrastructure that will enable them to address these challenges. The new resources will include a physical environment and a virtual environment to enable human-centered investigation, tools to capture human multimodal language behaviors that include human speech, eye gaze, and gesture during situated human robot dialogue, and systems to support Wizard-of-Oz experiments, data collection, and data analysis. The integration of a physical world and a virtual world is an innovation of the new infrastructure. Limitations of sensor and effector technology often make it difficult or expensive to change robot configurations and implement desired behaviors. The virtual world paradigm allows efficient and high fidelity simulation of the physical world and robots, as well as studies on multimodal language behavior under many different conditions which are otherwise difficult to obtain in the physical world. The new infrastructure will enable a human-centered approach by facilitating a wide variety of controlled experiments. It will enable new empirical findings and provide a testbed for advanced techniques for multimodal language processing that are psycholinguistically plausible.&lt;br/&gt;&lt;br/&gt;Broader Impacts: The new infrastructure will provide tremendous research and collaborative opportunities for the PI and her colleagues at Michigan State University. It will have profound implications in enabling the next generation of social and cognitive robots. This infrastructure will also provide new and exciting training and education opportunities for students at MSU through research mentoring and curriculum development. It will bring new educational experiences to K-12 students and encourage broader participation in engineering through several outreach programs at MSU.</AbstractNarration>
    <MinAmdLetterDate>02/23/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>12/05/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0957039</AwardID>
    <Investigator>
      <FirstName>Joyce</FirstName>
      <LastName>Chai</LastName>
      <EmailAddress>jchai@cse.msu.edu</EmailAddress>
      <StartDate>02/23/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Michigan State University</Name>
      <CityName>East Lansing</CityName>
      <ZipCode>488242600</ZipCode>
      <PhoneNumber>5173555040</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Michigan</StateName>
      <StateCode>MI</StateCode>
    </Institution>
  </Award>
</rootTag>
