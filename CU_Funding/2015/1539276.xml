<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Neural-Cognitive Analysis of spatial scenes with competing, dynamic sound sources</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>335598</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Alumit Ishai</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project investigates neurocognitive mechanisms that extract important information from a mixture of sound sources. Imagine a day where you could no longer distinguish the honking horn of a car coming right at you from other street sounds. This cognitive ability to attend to one sound source while ignoring others presents an everyday challenge for people with hearing impairments. While the basic neural mechanisms for detecting and localizing single sounds are known, we do not know how the brain accomplishes auditory scene analysis with multiple sound sources. So far, studies have focused on lower brain centers in rodents and carnivores, while the neural mechanisms for source segregation are expected to be at higher levels, in the auditory cortex. This study will record the responses of single cortical neurons and conduct human-subject experiments for the same acoustic scenarios. Based on the integration of these results, a functional auditory model will be developed. This will provide new scientific insights and enable intelligent algorithms for hearing aids, social robotics, and surveillance systems. The project will provide research opportunities for graduate and undergraduate students and include outreach activities and online learning resources for high-school and college students to increase the public awareness of neuroscience. The research results and the model will be shared with the academic community. &lt;br/&gt;&lt;br/&gt;This proposal will use an interdisciplinary approach to gain understanding of the central mechanisms of auditory scene analysis by integrating psychoacoustical experiments with single-unit electrophysiology. The study will investigate how the auditory system localizes a target sound temporally embedded in a spatially separated masker. Single-unit recording will target the caudal region of the auditory cortex, the putative "where" pathway for complex sound analysis. We hypothesize that cortical activity represents both the old and new sounds, so that the internal representation of the "old" masking source can be subtracted from the overall mixture. This facilitates a clearer perception of the "new" target element, demonstrating a fundamental psychophysical phenomenon within auditory scene analysis. To test this hypothesis, we will identify the neural signals for individual sound sources separately and in combination. We will then interpret these signals based on the perceptual data gained from sound localization tests with multiple moving and stationary sound sources. Discovering the fundamental brain mechanisms for auditory scene analysis will provide new neurophysiological insight into a well-established psychophysical field and offer potential technical solutions for sound-source segregation.</AbstractNarration>
    <MinAmdLetterDate>08/18/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/18/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1539276</AwardID>
    <Investigator>
      <FirstName>Jonas</FirstName>
      <LastName>Braasch</LastName>
      <EmailAddress>braasj@rpi.edu</EmailAddress>
      <StartDate>08/18/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Rensselaer Polytechnic Institute</Name>
      <CityName>Troy</CityName>
      <ZipCode>121803522</ZipCode>
      <PhoneNumber>5182766000</PhoneNumber>
      <StreetAddress>110 8TH ST</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1699</Code>
      <Text>COGNEURO</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7252</Code>
      <Text>PERCEPTION, ACTION &amp; COGNITION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7298</Code>
      <Text>COLLABORATIVE RESEARCH</Text>
    </ProgramReference>
  </Award>
</rootTag>
