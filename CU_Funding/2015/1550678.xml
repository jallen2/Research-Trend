<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Auditory Navigation</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>300000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04010000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>SBE Off Of Multidisciplinary Activities</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Soo-Siang Lim</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>All animals must navigate and find their way in space, in order to find food and shelter and avoid harm. Humans overwhelmingly rely on visual landscape to learn spatial maps and navigate. Unfortunately, millions of blind people cannot do that. They can avoid obstacles using a walking stick but this does not provide information about the spatial layout on a larger scale, defined by visual landmarks such as pillars, buildings, mountains etc. Without this information about the visual landscape blind subjects cannot develop a sense of spatial map of the surrounding world and navigate within it. This inability to learn spatial maps is profoundly debilitating and has serious consequences for other forms of learning as well. &lt;br/&gt;&lt;br/&gt;The proposed project will test a novel and multidisciplinary solution that can be implemented using recently developed techniques developed by the Principal Investigator?s (PI's) laboratory. The researchers hypothesize that subjects could form navigational maps through an artificially created auditory landscape. To test this, the investigators will create a landscape defined only by auditory cues and ask subjects to navigate. This requires techniques to eliminate nonspecific cues such as light and smells that can accidentally provide spatial information. Using these recently developed techniques to eliminate such confounds and ensure that subjects are navigating only with auditory cues, the researchers will also develop data analysis methods to determine how well and how quickly the subjects are learning the auditory landscape. The results would provide valuable insights about whether mammals, even with the ones with good visual abilities in terms of their genetic heritage (e.g. humans), can learn to rely on the auditory cues alone to learn spatial maps. In the long run this information would be quite useful in helping blind people learn to navigate using auditory cues.</AbstractNarration>
    <MinAmdLetterDate>08/31/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/31/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1550678</AwardID>
    <Investigator>
      <FirstName>Mayank</FirstName>
      <LastName>Mehta</LastName>
      <EmailAddress>MayankMehta@UCLA.edu</EmailAddress>
      <StartDate>08/31/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Los Angeles</Name>
      <CityName>LOS ANGELES</CityName>
      <ZipCode>900952000</ZipCode>
      <PhoneNumber>3107940102</PhoneNumber>
      <StreetAddress>11000 Kinross Avenue, Suite 211</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7704</Code>
      <Text>Science of Learning Activities</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
