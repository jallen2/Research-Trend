<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>XPS: EXPL: DSD: A Memristive Hardware Platform for Large Scale Combinatorial Optimization</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>298283</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tao Li</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Mathematical optimization plays a vital role in virtually every scientific discipline. A 2013 report by the U.S. National Academy of Sciences (NAS) identifies optimization as one of the seven giants of statistical data analysis on massive data, while the U.S. Department of Energy (DOE) Office of Science reports that mathematical optimization will increasingly be used in the exascale era. Solving large-scale optimization problems on massive datasets can require weeks or months of computation time on modern supercomputers, which regrettably deliver only a small fraction of the peak performance due to significant data movement overheads. Hardware and software innovations that can improve energy efficiency by orders of magnitude are needed before exascale platforms for mathematical optimization can become practical.&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This project embodies a radically different vision of the future, one where large scale combinatorial optimization problems are mapped onto a memory-centric, non-Von Neuman compute substrate and solved in situ within the memory cells, with orders of magnitude greater performance and energy efficiency than contemporary supercomputers. Recent developments in the resistive random access memory (RRAM) technology are leveraged to build an extremely low power, fast memory substrate for accelerating combinatorial optimization algorithms. RRAM is a memristive, non-volatile memory technology that provides FLASH-like density and DRAM-like read speeds. The project exploits the electrical properties of RRAM in combination with CMOS transistors to enable in situ optimization within the memory cells, thereby eliminating data movement between the memory arrays and the computational units, reducing the energy, and significantly increasing the performance. Novel algorithms will be developed to map problems from different scientific and engineering domains onto the proposed memristive hardware substrate. Software modules and libraries for memory allocation and partitioning; dynamic resource management; and hardware-software co-design will be developed to give the user control of the optimization process at runtime. At the hardware level, the accelerator employs a versatile organization of data arrays constructed from novel RRAM cells, capable not only of storing the data, but also of performing in situ computation on that data. The proposed research holds the promise of bringing about a transformative change in the performance and energy efficiency of exascale optimization frameworks, with tremendous positive fallout to science, technology, and society as a whole. Architecture and software innovations will be disseminated to the broader research community through published papers, as well as tutorials on the proposed framework and mapping algorithms. The educational component of the project involves training both graduate and undergraduate students in computer architecture, as well as a memory systems course that integrates the RRAM technology into the syllabus. The PI is also personally involved in local programs promoting the participation of women and underrepresented minorities in computer science and engineering, and has an ongoing effort to increase the enrollment of local minorities in University of Rochester's CS and ECE programs.</AbstractNarration>
    <MinAmdLetterDate>08/25/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/25/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1533762</AwardID>
    <Investigator>
      <FirstName>Engin</FirstName>
      <LastName>Ipek</LastName>
      <EmailAddress>ipek@cs.rochester.edu</EmailAddress>
      <StartDate>08/25/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Rochester</Name>
      <CityName>Rochester</CityName>
      <ZipCode>146270140</ZipCode>
      <PhoneNumber>5852754031</PhoneNumber>
      <StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8283</Code>
      <Text>Exploiting Parallel&amp;Scalabilty</Text>
    </ProgramElement>
  </Award>
</rootTag>
