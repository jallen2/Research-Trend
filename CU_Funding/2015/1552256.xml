<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Collaborative Research: Exploring Models for Conveying Imminent Robot Failures to Allow for Human Intervention</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>117521</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>In this exploratory research, the PIs will seek to advance the state of the science on how best to convey a robot's imminent failure to a human (whether an operator, supervisor, or bystander), in a manner that could allow the human to intervene as effectively as possible to prevent the failure. This project has the potential to dramatically increase the safety of humans in and around autonomous robots and vehicles. Specific goals are to discover design principles for robot systems with respect to conveying failure, and to identify methods for expressing failure so that humans react appropriately. The research will focus on three use cases: remote operation, co-located operation, and bystander interaction. To these ends, the team will utilize a variety of robots in order to support different applications and movement scales. Robots available to the team include small and mid-size unmanned ground vehicles, human-scale torso robots, a robot wheelchair, a telepresence robot, and an autonomous Jeep. Project outcomes will impact the field of human-robot interaction and the future use of robots in many application domains, particularly those of mobile and manipulation robots, including autonomous vehicles, factory robots, and assistive technology, by enhancing productivity and task performance, increasing personal safety for those who work in hazardous occupations, and improving the lives of persons with disabilities.&lt;br/&gt;&lt;br/&gt;The PIs' core research questions are informed by their substantial prior work with task-oriented robots. Based on that experience and other studies, they argue that the following three main factors strongly influence user actions during robot failure: perceived risk (e.g., a robot that crashes frequently is generally perceived as a high risk robot), perceived severity (e.g., the failure of a small robot made of soft materials is generally perceived as less severe than that of a full body humanoid robot), and role (e.g., is the user an operators or a bystander). Unexplored research questions about the manner in which these factors impact failure include. How do these factors, both independently and in combination, influence HRI during robot failures? How do humans utilize these factors during robot failure, and does this utilization have high variability or are humans very consistent? These factors will be used as independent variables during studies which will advance knowledge in three core areas: formulation and validation of generalizable quantitative and qualitative metrics for measuring a person's response to an imminent failure in a robot system; discovery of appropriate ways to communicate failure states to humans; and initial development of common design guidelines for handling failures. The primary goal is to make it easier for humans to rapidly understand failure events and to act or assist appropriately in a timely manner. The PIs are specifically focused on the human-robot interaction aspect of robot failures. As such, they will track literature and research on diagnosing failures, but will not develop new systems or concepts for this step. Instead, the team will seek appropriate and effective ways to convey failures to humans, appropriate human responses during failures, and appropriate failure states when human action is not possible or is insufficient.</AbstractNarration>
    <MinAmdLetterDate>08/25/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>05/18/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1552256</AwardID>
    <Investigator>
      <FirstName>Aaron</FirstName>
      <LastName>Steinfeld</LastName>
      <EmailAddress>steinfeld@cmu.edu</EmailAddress>
      <StartDate>08/25/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
  </Award>
</rootTag>
