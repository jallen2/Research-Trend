<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>UNS: Collaborative Research: Prosodic Control of Speech Synthesis for Assistive Communication in Severe Paralysis</AwardTitle>
    <AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2018</AwardExpirationDate>
    <AwardAmount>165080</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07020000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Chem, Bioeng, Env, &amp; Transp Sys</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Alexander Leonessa</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>1510563(Stepp) &amp; 1509791 (Koch Fager)&lt;br/&gt;&lt;br/&gt;This work will develop and evaluate a system to allow individuals with unintelligible speech due to severe paralysis to control a speech synthesizer that includes prosody (changes in the pitch, loudness, and duration in speech that convey meaning). This advancement to the synthetic speech and the ease of its control by users will facilitate improved functionality of clinical communication systems, thus improving the quality of life of users. Natural and intelligible speech production in these individuals will increase their ability to participate actively in society and empower them to self-advocate for their own medical management.&lt;br/&gt;&lt;br/&gt;The research objective of this proposal is to test the hypothesis that providing users of alternative and augmentative communication (AAC) with a method for prosodic control will result in speech synthesis that is more natural to listeners and provides greater function to users. Up to 1.2% of the population is unable to meet daily communication needs using typical speech due to stroke or other neurological injury, requiring AAC to meet their communication needs. Their quality of life is strongly dependent on access to this communication, both for social interaction as well as to relay information about urgent medical needs. The most advanced AAC devices incorporate speech synthesis, allowing the users to communicate orally with others. However, the resulting synthetic speech is both unnatural and difficult for others to understand, and is often described as "robotic". Specifically, synthetic speech does not vary in pitch, loudness, or rhythm, the prosodic features utilized in typical speech to relay emotional state, utterance form (statement vs. question), irony, and emphasis.&lt;br/&gt;Asking AAC users to control each of these dimensions individually would result in an intractably slow and complex system, an unacceptable burden for individuals who already have considerably reduced communication rates. Instead, this project will leverage the fact that typical speech predictably uses these prosodic markers (pitch, loudness, rhythm) in concert. A novel AAC interface will be developed to allow users to modify the overall "stress" of synthetic speech output as a single dimension, in order to provide easily controlled, natural, and intelligible speech synthesis. The co-PIs will use their combined expertise in speech technology, clinical application of AAC, and real-time control of human-machine-interfaces to enable essential advancements in AAC technology to achieve three goals. In Research Goal 1, a multi-stress speech bank for concatenative speech synthesis will be created via a novel interactive procedure in which speech productions of healthy speakers are "misunderstood", thus prompting speakers to naturally emphasize specific target sounds in their repeated responses. This will result in a bank of triphones (sounds with a specific left and right context, based on surrounding sounds) with all potential combinations of sounds and stresses. Research Goal 2 is to develop an AAC interface that allows users to select phonemes (individual sounds of speech) using two-dimensional cursor control (e.g., head-tracking, eye-tracking) in which the stress of individual phonemes will be based on cursor dwell time. In Research Goal 3, the functionality of the AAC interface will be evaluated by testing its effect on the naturalness of communicative interactions.</AbstractNarration>
    <MinAmdLetterDate>07/15/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>05/19/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1510563</AwardID>
    <Investigator>
      <FirstName>Cara</FirstName>
      <LastName>Stepp</LastName>
      <EmailAddress>cstepp@bu.edu</EmailAddress>
      <StartDate>07/15/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Trustees of Boston University</Name>
      <CityName>BOSTON</CityName>
      <ZipCode>022151300</ZipCode>
      <PhoneNumber>6173534365</PhoneNumber>
      <StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>5342</Code>
      <Text>Gen &amp; Age Rel Disabilities Eng</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>010E</Code>
      <Text>DISABILITY RES &amp; HOMECARE TECH</Text>
    </ProgramReference>
  </Award>
</rootTag>
