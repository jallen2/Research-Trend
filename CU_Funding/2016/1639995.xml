<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>E2CDA: Type II: Self-Adaptive Reservoir Computing with Spiking Neurons: Learning Algorithms and Processor Architectures</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2019</AwardExpirationDate>
    <AwardAmount>110914</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Sankar Basu</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>While computing has become increasingly data centric across many disciplines, conventional computer architectures have limited potential in meeting the escalating performance and energy efficiency needs in this era of data-driven science and engineering. This project aims to develop brain-inspired neural models of computation and adaptive processor architectures to enable intelligent data processing and learning in a wide range of applications. While being strongly interdisciplinary, this work will bridge neuroscience, artificial neural networks, computer architecture, and hardware engineering. The planned research will provide rich training and educational opportunities to students, and produce new curriculum. Research participation from undergraduate and underrepresented students will be promoted. The outcomes of this project will be broadly disseminated. Research collaboration with the US industry will be actively pursued via interaction with the Semiconductor Research Corporation. &lt;br/&gt;&lt;br/&gt;This work is aimed at attaining brain-like learning performance by imitating how the brain represents, processes, and learns from information, and more specifically, by developing models of computation based on the third-generation spiking neural networks, and efficient adaptive processor architectures. Within the framework of so called reservoir computing, the proposed neural models mimic key characteristics of the brain such as information processing based on spike timing. Furthermore, this project will develop brain-inspired learning mechanisms to allow training of complex recurrent spiking neural networks. Self-adaptive processor architectures with integrated on-chip learning, light-weight runtime learning performance prediction, and energy management will be developed to maximize system energy efficiency while providing a guarantee of performance.</AbstractNarration>
    <MinAmdLetterDate>08/26/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>08/26/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1639995</AwardID>
    <Investigator>
      <FirstName>Peng</FirstName>
      <LastName>Li</LastName>
      <EmailAddress>pli@tamu.edu</EmailAddress>
      <StartDate>08/26/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Texas A&amp;M Engineering Experiment Station</Name>
      <CityName>College Station</CityName>
      <ZipCode>778454645</ZipCode>
      <PhoneNumber>9798477635</PhoneNumber>
      <StreetAddress>TEES State Headquarters Bldg.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>015Y</Code>
      <Text>Energy Efficient Computing: fr</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7945</Code>
      <Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
    </ProgramReference>
  </Award>
</rootTag>
