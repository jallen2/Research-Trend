<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: High Confidence, Efficient Learning Under Rich Task Specifications</AwardTitle>
    <AwardEffectiveDate>08/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2019</AwardExpirationDate>
    <AwardAmount>470000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Hector Munoz-Avila</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Artificially intelligent machines such as autonomous vehicles and personal robots are poised to contribute in many economic sectors, but cannot be deployed on a large scale without measurable confidence that they will operate correctly. This is especially true for safety-critical systems in which humans could be injured or infrastructure could be damaged by incorrect behavior. The proposed research will address this key issue by developing methods that allow intelligent agents to learn to perform challenging tasks and adapt to new situations, while simultaneously providing strong guarantees of correctness and safety. Once deployed, these future robotic systems will have broad impacts on society ranging from automating small manufacturing to giving new freedom to disabled and elderly populations through safe and personalized in-home care. The proposed robotics applications will additionally create opportunities for interactive educational K-12 programs to encourage interest in STEM areas, as well as undergraduate and graduate education.&lt;br/&gt;&lt;br/&gt;Towards these goals, the proposed work focuses on three primary research thrusts: 1) We will design safe learning algorithms that provide theoretical probabilistic satisfaction and data efficiency guarantees over both the expected reward of a policy and its correctness with respect to a high-level specification. 2) In order to account for the gap between theoretical and practical efficiency in learning, we will develop model-based and model-free off-policy evaluation methods that leverage active sampling strategies and bootstrapping to achieve practical efficiency. 3) We will develop hybrid techniques that combine and amplify the advantages of both strong theoretical and efficient practical guarantees. The merit of the proposed algorithms will be systematically evaluated on complex, real-world problems in robotic reconfigurable manufacturing that require learning optimized, yet safe policies with a high degree of confidence in settings with low-to-medium quantities of available data.</AbstractNarration>
    <MinAmdLetterDate>06/10/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>06/10/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1617639</AwardID>
    <Investigator>
      <FirstName>Scott</FirstName>
      <LastName>Niekum</LastName>
      <EmailAddress>sniekum@cs.utexas.edu</EmailAddress>
      <StartDate>06/10/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Ufuk</FirstName>
      <LastName>Topcu</LastName>
      <EmailAddress>utopcu@utexas.edu</EmailAddress>
      <StartDate>06/10/2016</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
