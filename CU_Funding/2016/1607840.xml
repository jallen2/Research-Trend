<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>New algorithms for consistent model selection beyond linear models</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2019</AwardExpirationDate>
    <AwardAmount>90323</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Nandini Kannan</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Statistical model building is an important part of scientific discovery. In the big data era, high dimensional data arise frequently. Model selection in the presence of high dimensional features in the framework of linear models, generalized linear models, and models with censored data has been a very active area of research in recent years. The PI aims to develop new algorithms for model selection, within a Bayesian computational framework, that are scalable for high dimensional problems. The PI motivates the proposed research through collaborations with scientists in atmospheric sciences, genetics, and kinesiology, and aims to develop methodologies that are broadly applicable in statistical modeling and data analysis. &lt;br/&gt;&lt;br/&gt;Much of the recent work has focused on shrinkage through penalization or regularization. Bayesian computational methods, when interpreted broadly, play a valuable role in statistics, including model selection and estimation, but face important hurdles in high dimensional statistics, both in theoretical intricacy and in computational scalability. The PI aims to develop a theoretical framework to demonstrate model selection consistency from the frequentist perspective, which offers interesting insights into why Bayesian model selection methods can provide an asymptotic approximation to the L0 penalty. An important part of the proposed work is the development of a modified Gibbs sampler in the selection of sparse models that is much more scalable than standard MCMC algorithms in the presence of high dimensional variables. The Bayesian methods are especially useful in problems with non-convex objective functions, where Bayesian computation methods can be more robust in performance than direct optimization. A primary application of such a problem considered in the project is quantile regression for censored data. In addition to model selection, the PI proposes a new estimation method for censored quantile regression that promises to be computationally and statistically efficient. Equally importantly, the new method adapts easily to general forms of censoring that other estimation methods have found difficult to handle. The PI will continue integrating research with education by working with PhD students and by providing research experiences for undergraduate students. The research output will be properly disseminated through conferences and workshops and through publication in widely read journals in statistical science.</AbstractNarration>
    <MinAmdLetterDate>05/24/2016</MinAmdLetterDate>
    <MaxAmdLetterDate>05/24/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1607840</AwardID>
    <Investigator>
      <FirstName>Xuming</FirstName>
      <LastName>He</LastName>
      <EmailAddress>xmhe@umich.edu</EmailAddress>
      <StartDate>05/24/2016</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Michigan Ann Arbor</Name>
      <CityName>Ann Arbor</CityName>
      <ZipCode>481091274</ZipCode>
      <PhoneNumber>7347636438</PhoneNumber>
      <StreetAddress>3003 South State St. Room 1062</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Michigan</StateName>
      <StateCode>MI</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1269</Code>
      <Text>STATISTICS</Text>
    </ProgramElement>
  </Award>
</rootTag>
