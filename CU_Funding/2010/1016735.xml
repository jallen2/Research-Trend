<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Small: Adapting a Natural Logic Reasoning Platform to the Task of Entailment Inference</AwardTitle>
    <AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2012</AwardExpirationDate>
    <AwardAmount>149999</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Current AI systems still lack the knowledge and reasoning &lt;br/&gt;abilities needed to handle the semantic subtleties of language &lt;br/&gt;and the thematic breadth of human discourse and thinking.&lt;br/&gt;This project is developing a basic repertoire of lexical and&lt;br/&gt;other general knowledge for use in a powerful inference engine &lt;br/&gt;(EPILOG) designed expressly to support unrestricted language &lt;br/&gt;understanding and reasoning.&lt;br/&gt;&lt;br/&gt;The methods being employed exploit the insights into language-based&lt;br/&gt;inference gained in recent years in the area of "natural Logic",&lt;br/&gt;which makes systematic use of word-level and structural entailment&lt;br/&gt;properties of language. These are easily modeled in EPILOG, which&lt;br/&gt;uses a language-like meaning representation (Episodic Logic). Some&lt;br/&gt;very general semantic properties are being manually encoded, and in &lt;br/&gt;addition, large numbers of knowledge items are being extracted&lt;br/&gt;computationally from lexical resources such as WordNet and VerbNet,&lt;br/&gt;and from word similarity or paraphrase clusters derived from large &lt;br/&gt;text corpora.&lt;br/&gt;&lt;br/&gt;The expected result is a knowledge base of fundamental lexical and&lt;br/&gt;other commonsense knowledge that will allow demonstration of many&lt;br/&gt;previously infeasible language-based inferences, including both &lt;br/&gt;forward and backward reasoning and many multi-premise entailment &lt;br/&gt;inferences in existing test suites. This will significantly &lt;br/&gt;advance the state of the art in basic language understanding and &lt;br/&gt;in mechanizing "obvious inferences", with potential applications &lt;br/&gt;to intelligent dialogue-based agents (for question answering, &lt;br/&gt;tutoring, personal assistance, etc.), and to knowledge bootstrapping &lt;br/&gt;through machine reading. The results will be disseminated both &lt;br/&gt;through papers at conferences and in journals, and through web sites &lt;br/&gt;making available EPILOG and the newly developed knowledge bases.</AbstractNarration>
    <MinAmdLetterDate>09/16/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>09/16/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1016735</AwardID>
    <Investigator>
      <FirstName>Lenhart</FirstName>
      <LastName>Schubert</LastName>
      <EmailAddress>schubert@cs.rochester.edu</EmailAddress>
      <StartDate>09/16/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Rochester</Name>
      <CityName>Rochester</CityName>
      <ZipCode>146270140</ZipCode>
      <PhoneNumber>5852754031</PhoneNumber>
      <StreetAddress>518 HYLAN, RC BOX 270140</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>New York</StateName>
      <StateCode>NY</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
  </Award>
</rootTag>
