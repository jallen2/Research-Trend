<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>DC: Small: Collaborative Research: DARE: Declarative and Scalable Recovery</AwardTitle>
    <AwardEffectiveDate>09/15/2010</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2013</AwardExpirationDate>
    <AwardAmount>190000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Hong Jiang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>One dominant characteristic of today's large-scale computing systems&lt;br/&gt;is the prevalence of large storage clusters. Storage clusters at the&lt;br/&gt;scale of hundreds or thousands of commodity machines are&lt;br/&gt;increasingly being deployed. At companies like Amazon, Google, Yahoo,&lt;br/&gt;and others, thousands of nodes are managed as a single system.&lt;br/&gt;&lt;br/&gt;As large clusters have brought many benefits, they also bring a new&lt;br/&gt;challenge: a growing number and frequency of failures that must be&lt;br/&gt;managed. Bits, sectors, disks, machines, racks, and many other&lt;br/&gt;components fail. With millions of servers and hundreds of data&lt;br/&gt;centers, there are millions of opportunities for these components to&lt;br/&gt;fail. Failing to deal with failures will directly impact the&lt;br/&gt;reliability and availability of data and jobs.&lt;br/&gt;&lt;br/&gt;Unfortunately, we still hear data-loss stories even recently. For&lt;br/&gt;example, in March 2009, Facebook lost millions of photos due to&lt;br/&gt;simultaneous disk failures that "should" rarely happen at the same&lt;br/&gt;time (but it happened); in July 2009, a large bank was fined a record&lt;br/&gt;total of 3 millions pounds after losing data on thousands of its&lt;br/&gt;customers; more recently, in October 2009, T-Mobile Sidekick, which&lt;br/&gt;uses Microsoft's cloud service, also lost its customer data. These&lt;br/&gt;incidents have shown that existing large-scale storage systems are&lt;br/&gt;still fragile to failures.&lt;br/&gt;&lt;br/&gt;To address the challenges of large-scale recovery, the goal of this&lt;br/&gt;project is to: (1) seek the fundamental problems of recovery in&lt;br/&gt;today's scalable world of computing, (2) improve the reliability,&lt;br/&gt;performance, and scalability of existing large-scale recovery, and (3)&lt;br/&gt;explore formally grounded languages to empower rigorous specification&lt;br/&gt;of recovery properties and behaviors. Our vision is to build systems&lt;br/&gt;that "DARE to fail": systems that deliberately fail themselves,&lt;br/&gt;exercise recovery routinely, and enable easy and correct deployment of&lt;br/&gt;new recovery policies.&lt;br/&gt;&lt;br/&gt;For more information, please visit this website:&lt;br/&gt;http://boom.cs.berkeley.edu/dare/</AbstractNarration>
    <MinAmdLetterDate>09/15/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>09/15/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1017073</AwardID>
    <Investigator>
      <FirstName>Andrea</FirstName>
      <LastName>Arpaci-Dusseau</LastName>
      <EmailAddress>dusseau@cs.wisc.edu</EmailAddress>
      <StartDate>09/15/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Wisconsin-Madison</Name>
      <CityName>MADISON</CityName>
      <ZipCode>537151218</ZipCode>
      <PhoneNumber>6082623822</PhoneNumber>
      <StreetAddress>21 North Park Street</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Wisconsin</StateName>
      <StateCode>WI</StateCode>
    </Institution>
  </Award>
</rootTag>
