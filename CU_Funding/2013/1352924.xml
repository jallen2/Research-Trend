<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Enhancing Mobile Device Users' Levels of Situational Awareness through Tactile Feedback</AwardTitle>
    <AwardEffectiveDate>09/15/2013</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2015</AwardExpirationDate>
    <AwardAmount>96001</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>In this project the PI will explore a novel approach to allowing individuals to monitor their wider environment for potential obstacles and threats while engaged in a task where the eyes are occupied. Specifically, he will focus on mobile device users, who often perform visually-demanding tasks such as composing and reading text messages while ambulatory, so that they may fail to notice the presence of pedestrians, approaching vehicular traffic or other objects which they are at risk of encountering. The PI's approach is to present tactile feedback via a head-mounted interface in order to communicate the presence of obstacles. While situational awareness technologies have been designed to assist ambulatory users, alerts are often presented using visual or auditory feedback. But if the user is engaged with a mobile task precious time may be taken to identify the presence of graphical indicators, whereas auditory alerts may be masked by environmental sounds to that the user misses vital cues. The PI argues that tactile feedback offers considerable advantages when the user's other senses are blocked or restricted, and there is the additional benefit that tactile alerts can be presented discreetly without drawing attention by others. To test these hypotheses, the PI will conduct a sequence of studies to determine whether it is possible to design tactile cues that are effective in supporting informed decisions by the user. Project outcomes will include design of a head-mounted interface prototype using object-recognition and sensor-based technologies to track obstacles in the user's vicinity, along with innovative tactile interface design guidelines. &lt;br/&gt;&lt;br/&gt;Broader Impacts: This research will advance our understanding of issues relating to situational awareness among mobile device users, and it will also contribute to the body of knowledge on presenting tactile feedback to locations on the head (a field still in its infancy). The development of a library of tactile icons to convey concepts such as the number of obstacles, their location, and their proximity to the user, will have application across diverse domains.</AbstractNarration>
    <MinAmdLetterDate>09/04/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>09/04/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1352924</AwardID>
    <Investigator>
      <FirstName>Ravi</FirstName>
      <LastName>Kuber</LastName>
      <EmailAddress>rkuber@umbc.edu</EmailAddress>
      <StartDate>09/04/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Maryland Baltimore County</Name>
      <CityName>Baltimore</CityName>
      <ZipCode>212500002</ZipCode>
      <PhoneNumber>4104553140</PhoneNumber>
      <StreetAddress>1000 Hilltop Circle</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Maryland</StateName>
      <StateCode>MD</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
