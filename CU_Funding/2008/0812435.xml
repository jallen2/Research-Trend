<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI-Small: Graph-Based Learning for Speech Processing</AwardTitle>
    <AwardEffectiveDate>08/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2012</AwardExpirationDate>
    <AwardAmount>427198</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Graph-Based Learning for Speech Processing&lt;br/&gt;&lt;br/&gt;Over the past decades much research has been invested in automatic speech&lt;br/&gt;processing, and current speech processing systems often achieve remarkably &lt;br/&gt;low error rates. However, systems are still dependent on matched training and &lt;br/&gt;test corpora, and their performance deteriorates rapidly when faced with&lt;br/&gt;test conditions that differ from the training data. In the machine learning &lt;br/&gt;community, many novel algorithms have recently been proposed to better &lt;br/&gt;incorporate information from unlabeled test data into the learning and &lt;br/&gt;classification process. Most of these techniques scale poorly to large tasks &lt;br/&gt;and thus seem unsuitable for speech processing. This project investigates&lt;br/&gt;the applicability of one recently developed paradigm, graph-based&lt;br/&gt;learning (GBL), for automatic speech recognition. In particular, it &lt;br/&gt;uses GBL as an adaptation framework where acoustic classifiers are &lt;br/&gt;constrained to yield outputs that vary smoothly along underlying data&lt;br/&gt;manifolds characterizing the test data. The project addresses the &lt;br/&gt;core problems of poor scalability and computational complexity of GBL &lt;br/&gt;by using data clustering and subselection techniques as well as &lt;br/&gt;sparse matrix computation. Various ways of incorporating domain &lt;br/&gt;information (e.g. temporal or higher-level prosodic information) &lt;br/&gt;into graph construction are evaluated, including the use of multiple, &lt;br/&gt;combined similarity measures for graph construction. Finally, online,&lt;br/&gt;incremental GBL techniques are being investigated in order to &lt;br/&gt;facilitate real-time processing. The outcome of this project is &lt;br/&gt;expected to significantly improve the accuracy and robustness of &lt;br/&gt;speech processing systems. Furthermore, it will contribute to improving &lt;br/&gt;the scalability of semi-supervised learning algorithms in general and&lt;br/&gt;thus facilitate their application to related pattern recognition fields.</AbstractNarration>
    <MinAmdLetterDate>07/23/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>07/23/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0812435</AwardID>
    <Investigator>
      <FirstName>Katrin</FirstName>
      <LastName>Kirchhoff</LastName>
      <EmailAddress>katrin@ee.washington.edu</EmailAddress>
      <StartDate>07/23/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Washington</Name>
      <CityName>Seattle</CityName>
      <ZipCode>981950001</ZipCode>
      <PhoneNumber>2065434043</PhoneNumber>
      <StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Washington</StateName>
      <StateCode>WA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
  </Award>
</rootTag>
