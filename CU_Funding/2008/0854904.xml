<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>II-New: High-Definition and Immersive Acquisition, Processing, and Display Equipment for Video Processing and Vision Science Research and Education</AwardTitle>
    <AwardEffectiveDate>07/15/2009</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2012</AwardExpirationDate>
    <AwardAmount>205912</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Jie Yang</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>New, state-of-the-art video quality assessment (VQA) algorithms will be developed that are explicitly designed for use on High Definition (HD) video streams. These will be designed using perceptual criteria and taking into account such human factors as head and eye position. An open database of raw digital HD videos will be developed, along with multiple distorted versions of each video and human subjective scores on the distorted videos. Since HD videos are often resized for display on smaller screen, scalable VQA and IQA algorithms will also be developed that will for the first time, be able to assess the quality of images or videos, in a perceptually significant way that have been scaled or resized from their original dimensions. The development of successful HD Video Quality Assessment (VQA) algorithms that correlate highly with visual perception will represent a major advance in video engineering. The construction of an HD video quality database will be the first of is kind, and certainly heavily accessed by researchers around the world. Prior work by this group on non-HD VQA has resulted in some of the most-highly cited research in the image processing field in the past 20 years. It is anticipated that publications from this work will likewise be highly influential.&lt;br/&gt;The equipment and developed algorithms will also be used as exemplars in the UT-Austin image and video processing educational program. The equipment will be used to generate numerous video processing teaching examples.</AbstractNarration>
    <MinAmdLetterDate>07/10/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>07/10/2009</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0854904</AwardID>
    <Investigator>
      <FirstName>Wilson</FirstName>
      <LastName>Geisler</LastName>
      <EmailAddress>geisler@psy.utexas.edu</EmailAddress>
      <StartDate>07/10/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Alan</FirstName>
      <LastName>Bovik</LastName>
      <EmailAddress>bovik@ece.utexas.edu</EmailAddress>
      <StartDate>07/10/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Lawrence</FirstName>
      <LastName>Cormack</LastName>
      <EmailAddress>Cormack@mail.utexas.edu</EmailAddress>
      <StartDate>07/10/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
  </Award>
</rootTag>
