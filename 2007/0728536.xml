<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>The Computational Intractability of Machine Learning Tasks</AwardTitle>
    <AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>02/29/2012</AwardExpirationDate>
    <AwardAmount>250000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Dmitry Maslov</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This research involves understanding the computational complexity of&lt;br/&gt;fundamental machine learning problems. In particular, the&lt;br/&gt;investigators study which classic learning problems are unlikely to&lt;br/&gt;admit efficient solutions. In terms of broader impact, this line of&lt;br/&gt;research aids practitioners and algorithm designers as it outlines&lt;br/&gt;fundamental stumbling blocks for creating powerful learning systems.&lt;br/&gt;For example, can we reduce difficult open problems from cryptography&lt;br/&gt;(e.g., factoring) and complexity theory (e.g., NP-complete languages)&lt;br/&gt;to certain problems in machine learning? If so, this provides strong&lt;br/&gt;evidence that particular machine learning problems are hopelessly&lt;br/&gt;intractable. Another avenue of research is to prove unconditional&lt;br/&gt;lower bounds on the resources required to infer functions in&lt;br/&gt;restricted learning models.&lt;br/&gt;&lt;br/&gt;The intellectual merit of the research lies in finding new reductions&lt;br/&gt;between problems in cryptography and complexity theory-- in particular&lt;br/&gt;communication complexity-- and problems from learning theory. For&lt;br/&gt;example, the PI studies the impact of lattice-based cryptography in&lt;br/&gt;machine learning and examines its implications for the DNF learning&lt;br/&gt;problem. Additionally, the PI researches the use of communication&lt;br/&gt;complexity to rule out learning simple concept classes via small sets&lt;br/&gt;of arbitrary features. We further delineate the role of Fourier&lt;br/&gt;analysis in proving lower bounds in the well known model of&lt;br/&gt;Statistical Query learning. Finally, this research investigates the&lt;br/&gt;relationships between NP-completeness and circuit complexity to&lt;br/&gt;general questions about proper learning and distribution-specific&lt;br/&gt;query learning.</AbstractNarration>
    <MinAmdLetterDate>08/24/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>08/24/2007</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0728536</AwardID>
    <Investigator>
      <FirstName>Adam</FirstName>
      <LastName>Klivans</LastName>
      <EmailAddress>klivans@cs.utexas.edu</EmailAddress>
      <StartDate>08/24/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
  </Award>
</rootTag>
