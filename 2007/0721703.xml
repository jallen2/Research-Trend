<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>NeTS-NoSS: Sensing in Three Dimensions with Smart Cameras</AwardTitle>
    <AwardEffectiveDate>09/01/2007</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2011</AwardExpirationDate>
    <AwardAmount>700000</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05050000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Computer and Network Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Darleen L. Fisher</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This project is building cooperating networks of cameras that can be used to reconstruct three-dimensional (3D) features, produce images from novel viewpoints, match trajectories or objects against known patterns, or combine these tasks to provide a powerful, flexible monitoring system.&lt;br/&gt;&lt;br/&gt;High data rates and precise calibration requirements present challenges that are not faced by earlier, simpler sensor networks.&lt;br/&gt;The bandwidth required to transmit video data from hundreds or thousands of cameras to a central location for processing would be enormous.&lt;br/&gt;&lt;br/&gt;Instead, this project is building low-power smart cameras that process video data in real time, extracting features and 3D geometry from the raw images of cooperating cameras. These compressed results, still somewhat bandwidth intensive, are stored in the network until required by users. Content-based routing techniques enable queries against a space-time representation of the data. Query processing occurs in-network, greatly reducing bandwidth requirements.&lt;br/&gt;&lt;br/&gt;Camera networks must calibrate precisely, discover and track objects, route view requests to viable cameras, and avoid unnecessary transmissions. Content-routing techniques that will allow cameras to find common features---critical for calibration, search, and tracking.&lt;br/&gt;These techniques allow features to be stored and processed near their acquisition point, avoiding wasted communication. Integrated, application-specific compression techniques further reduce overhead.&lt;br/&gt;&lt;br/&gt;This project also aims to simplify the engineering effort in building 3D sensornet applications. A space-time ``cube'' abstraction is used to represent the data of the entire sensornet, throughout time. A declarative language is used to specify feature patterns for search and tracking. High-level features can be described as compositions in space-time of simpler features. These descriptions are compiled to use the data-centric protocols to implement data selection, search, or tracking without data centralization.</AbstractNarration>
    <MinAmdLetterDate>08/20/2007</MinAmdLetterDate>
    <MaxAmdLetterDate>09/17/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0721703</AwardID>
    <Investigator>
      <FirstName>Gabriel</FirstName>
      <LastName>Taubin</LastName>
      <EmailAddress>taubin@brown.edu</EmailAddress>
      <StartDate>08/20/2007</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>John</FirstName>
      <LastName>Jannotti</LastName>
      <EmailAddress>jj@cs.brown.edu</EmailAddress>
      <StartDate>08/20/2007</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Ugur</FirstName>
      <LastName>Cetintemel</LastName>
      <EmailAddress>ugur@cs.brown.edu</EmailAddress>
      <StartDate>08/20/2007</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Brown University</Name>
      <CityName>Providence</CityName>
      <ZipCode>029129002</ZipCode>
      <PhoneNumber>4018632777</PhoneNumber>
      <StreetAddress>BOX 1929</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Rhode Island</StateName>
      <StateCode>RI</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>1640</Code>
      <Text>INFORMATION TECHNOLOGY RESEARC</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7363</Code>
      <Text>RES IN NETWORKING TECH &amp; SYS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7363</Code>
      <Text>RES IN NETWORKING TECH &amp; SYS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7390</Code>
      <Text>NETWORKING OF SENSOR SYSTEMS (NOSS)</Text>
    </ProgramReference>
  </Award>
</rootTag>
