<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CISE Research Instrumentation: Data-Driven Modeling for Real-Time Interaction and Animation</AwardTitle>
    <AwardEffectiveDate>09/01/2000</AwardEffectiveDate>
    <AwardExpirationDate>01/31/2003</AwardExpirationDate>
    <AwardAmount>48394</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05060200</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>DIVISION OF EXPERIMENTAL &amp; INTEG ACTIVIT</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Rita V. Rodriguez</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>9818287&lt;br/&gt;Hodgins, Jessica K.&lt;br/&gt;Atkeson, Christopher G.&lt;br/&gt;Georgia Institute of Technology&lt;br/&gt;&lt;br/&gt;CISE Research Instrumentation: Data-Driven Modeling for Real-time Interaction and Animation&lt;br/&gt;&lt;br/&gt;This research instrumentation enables research projects in:&lt;br/&gt;&lt;br/&gt;- Perception of Action&lt;br/&gt;- Learning from Demonstration&lt;br/&gt;- Animating with Experimentally Determined Parameters, and&lt;br/&gt;- Modeling Facial Expressions&lt;br/&gt;&lt;br/&gt;To support the aforementioned projects, for the capture, modeling, recognition, and generation of human motion, this award contributes to the purchase of motion capture equipment, graphics workstations, and digital cameras at College of Computing in Georgia Institute of Technology. The equipment will be used for several projects aimed at making it easy to create, control, and interact with artificial humans in interactive&lt;br/&gt;environments for training and entertainment. The cameras and motion capture equipment will capture full body and facial motion of the users. The processing power of the graphics workstations and other available&lt;br/&gt;multi-processors will be used to create data-driven models for recognition and generation of human actions ranging from full body motions such as a tennis swing to subtle facial expressions. The power of this technology will be demonstrated by constructing interactive environments in which the cameras and motion capture equipment will be used for on-line recognition of user actions and the graphics workstation will be used to animate human figures in real-time, based on the models derived off-line. The prototype applications will be environments where interactivity and realism are key, such as training environments for physical tasks and animation of highly interactive and responsive characters.</AbstractNarration>
    <MinAmdLetterDate>09/24/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>09/24/2002</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0242482</AwardID>
    <Investigator>
      <FirstName>Jessica</FirstName>
      <LastName>Hodgins</LastName>
      <EmailAddress>jkh@cs.cmu.edu</EmailAddress>
      <StartDate>09/24/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Carnegie-Mellon University</Name>
      <CityName>PITTSBURGH</CityName>
      <ZipCode>152133815</ZipCode>
      <PhoneNumber>4122689527</PhoneNumber>
      <StreetAddress>5000 Forbes Avenue</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
  </Award>
</rootTag>
