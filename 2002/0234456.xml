<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>DIVER: Distributed Collaborative Analysis of Video Records in the Human Sciences</AwardTitle>
    <AwardEffectiveDate>09/15/2002</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2003</AwardExpirationDate>
    <AwardAmount>97133</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11090000</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Research On Learning</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gregg E. Solomon</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This award supports the design and prototype development of a Web-based application for collaborative analysis of video records in the human sciences. This application, DIVER (Digital Interactive Video Exploration and Reflection), addresses a critical need for .collaboratory. functions in the human sciences, where common tools and a shared corpus of human interaction datasets can be used for investigating questions of theory and practice. The proposed effort will leverage an NSF-MRI Award (NSF-0216334) for related work and capitalize on an NSF-funded Center for Innovative Learning Technologies (CILT) workshop on Digital Video Inquiry in late November 2002. The CILT workshop will enable the introduction of the tool to a community of NSF project researchers, graduate students, and teacher-researchers, and to engage them in the further design and development of DIVER. This feedback is crucial for an application that is intended to help constitute and serve a community of users. The DIVER application will consist of a server holding analyses of video data, consisting of video sources and a series of annotated selections cropped in both time and space. Viewers of a DIVER analysis will be able to respond using threaded discussions attached to particular scenes from the original analysis, and they can return to the base video clip to create their own selections as their responses warrant. Several substantial technical issues, primary among them the manipulation of multimedia records in a web browser environment, and the storage, indexing, and retrieval of complex annotated multimedia documents need to be resolved.</AbstractNarration>
    <MinAmdLetterDate>09/14/2002</MinAmdLetterDate>
    <MaxAmdLetterDate>09/14/2002</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0234456</AwardID>
    <Investigator>
      <FirstName>Roy</FirstName>
      <LastName>Pea</LastName>
      <EmailAddress>roypea@stanford.edu</EmailAddress>
      <StartDate>09/14/2002</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stanford University</Name>
      <CityName>Palo Alto</CityName>
      <ZipCode>943041212</ZipCode>
      <PhoneNumber>6507232300</PhoneNumber>
      <StreetAddress>3160 Porter Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1666</Code>
      <Text>RESEARCH ON LEARNING &amp; EDUCATI</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9177</Code>
      <Text>ELEMENTARY/SECONDARY EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9237</Code>
      <Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>SMET</Code>
      <Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
