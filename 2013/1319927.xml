<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CIF: Small: Sparsity and Scarcity in High-Dimensional Point Processes</AwardTitle>
    <AwardEffectiveDate>07/01/2013</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2014</AwardExpirationDate>
    <AwardAmount>386331</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John Cozzens</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A wide variety of important applications rely upon our ability to quickly and accurately understand the physical world using a meager supply of event-based data. Such data arise when indirect observations of a physical phenomenon are collected by measuring discrete events (such as photons hitting a detector, sequence motifs appearing in a genome, packets traveling through an Internet router, neurons firing, or people interacting in a social network). The challenge here is to use extremely small numbers of random events to perform inference on the underlying high-dimensional phenomenon (e.g., the distribution of tissue in the body or the distribution of traffic in a network). In this case, conventional models of sensing and noise do not apply, and robust inference requires the development of both novel theoretical analyses and new computational methods.&lt;br/&gt;&lt;br/&gt;Point processes model random processes in which a realization consists of a collection of isolated events distributed across space or time. This research program is aimed at the development of new theory and methods for exploiting low-dimensional or sparse models of high-dimensional signal structure using scarce point process realizations. The theoretical results facilitate characterization of fundamental performance limits, such as bounds on the error of physically realizable models of inverse problems in photon-limited imaging and the performance gap between online and batch processing of streaming data. Furthermore, the methods themselves are practical and resource-efficient in a broad range of contexts, and being used by astronomers, microscopists, social scientists, and geneticists.&lt;br/&gt;Underlying these methods are techniques at the intersection of statistical signal processing, learning theory, sparse coding, nonlinear approximation theory, optical engineering, and optimization theory.</AbstractNarration>
    <MinAmdLetterDate>06/18/2013</MinAmdLetterDate>
    <MaxAmdLetterDate>06/18/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1319927</AwardID>
    <Investigator>
      <FirstName>Rebecca</FirstName>
      <LastName>Willett</LastName>
      <EmailAddress>becca.lu.willett@gmail.com</EmailAddress>
      <StartDate>06/18/2013</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Duke University</Name>
      <CityName>Durham</CityName>
      <ZipCode>277054010</ZipCode>
      <PhoneNumber>9196843030</PhoneNumber>
      <StreetAddress>2200 W. Main St, Suite 710</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>North Carolina</StateName>
      <StateCode>NC</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7936</Code>
      <Text>SIGNAL PROCESSING</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7936</Code>
      <Text>SIGNAL PROCESSING</Text>
    </ProgramReference>
  </Award>
</rootTag>
