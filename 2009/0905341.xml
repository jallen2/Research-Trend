<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>RI: Medium: Collaborative Research: Explicit Articulatory Models of Spoken Language, with Application to Automatic Speech Recognition</AwardTitle>
    <AwardEffectiveDate>07/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2013</AwardExpirationDate>
    <AwardAmount>378000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Proposal Title: RI: Medium: Collaborative Research: Explicit Articulatory Models of&lt;br/&gt;Spoken Language, with Application to Automatic Speech&lt;br/&gt;Recognition&lt;br/&gt;Institution: Toyota Technological Institute at Chicago&lt;br/&gt;Abstract Date: 05/22/09&lt;br/&gt;This award is funded under the American Recovery and Reinvestment Act of 2009&lt;br/&gt;(Public Law 111-5).&lt;br/&gt;One of the main challenges in automatic speech recognition is variability in speaking&lt;br/&gt;style, including speaking rate changes and coarticulation. Models of the articulators&lt;br/&gt;(such as the lips and tongue) can succinctly represent much of this variability. Most&lt;br/&gt;previous work on articulatory models has focused on the relationship between acoustics&lt;br/&gt;and articulation, but more significant improvements require models of the hidden&lt;br/&gt;articulatory state structure. This work has both a technological goal of improving&lt;br/&gt;recognition and a scientific goal of better understanding articulatory phenomena.&lt;br/&gt;The project considers larger model classes than previously studied. In particular, the&lt;br/&gt;project develops graphical models, including dynamic Bayesian networks and&lt;br/&gt;conditional random fields, designed to take advantage of articulatory knowledge. A new&lt;br/&gt;framework for hybrid directed and undirected graphical models is being developed, in&lt;br/&gt;recognition of the benefits of both directed and undirected models, and of both&lt;br/&gt;generative and discriminative training. The project activities include major extension of&lt;br/&gt;earlier articulatory models with context modeling, asynchrony structures, and&lt;br/&gt;specialized training; development of factored conditional random field models of&lt;br/&gt;articulatory variables; and discriminative training to alleviate word confusability.&lt;br/&gt;The scientific goal addresses questions about the ways in which articulatory trajectories&lt;br/&gt;vary in different contexts. Existing databases are used, and initial work in manual&lt;br/&gt;articulatory annotation is being extended. In addition, the project uses articulatory&lt;br/&gt;models to perform forced transcription of larger data sets, providing an additional&lt;br/&gt;resource for the research community. Other broad impacts include new models and&lt;br/&gt;techniques with applicability to other time-series modeling problems. Extending the&lt;br/&gt;applicability of speech recognition will help it fulfill its promise of enabling more efficient&lt;br/&gt;storage of and access to spoken information, and equalizing the technological playing&lt;br/&gt;field for those with hearing or motor disabilities.&lt;br/&gt;NATIONAL SCIENCE FOUNDATION&lt;br/&gt;Proposal Abstract&lt;br/&gt;Proposal:0905633 PI Name:Livescu, Karen&lt;br/&gt;Printed from eJacket: 06/10/09 Page 1 of 1</AbstractNarration>
    <MinAmdLetterDate>06/26/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>06/26/2009</MaxAmdLetterDate>
    <ARRAAmount>378000</ARRAAmount>
    <AwardID>0905341</AwardID>
    <Investigator>
      <FirstName>Jeffrey</FirstName>
      <LastName>Bilmes</LastName>
      <EmailAddress>bilmes@ee.washington.edu</EmailAddress>
      <StartDate>06/26/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Washington</Name>
      <CityName>Seattle</CityName>
      <ZipCode>981950001</ZipCode>
      <PhoneNumber>2065434043</PhoneNumber>
      <StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Washington</StateName>
      <StateCode>WA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7924</Code>
      <Text>MEDIUM PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9215</Code>
      <Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>6890</Code>
      <Text>RECOVERY ACT ACTION</Text>
    </ProgramReference>
  </Award>
</rootTag>
