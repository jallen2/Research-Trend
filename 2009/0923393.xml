<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>MRI: Development of a Next-Generation Interactive Virtual-Reality Display Environment for Science</AwardTitle>
    <AwardEffectiveDate>09/01/2009</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2015</AwardExpirationDate>
    <AwardAmount>1999983</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05090000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Advanced Cyberinfrastructure</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Edward Walker</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Proposal #: CNS 09-23393&lt;br/&gt;PI(s): Laidlaw, David H.; Hesthaven, Jan S.; Karnadiakis, George E.; van Dam, Andries&lt;br/&gt;Institution: Brown University &lt;br/&gt; Providence, RI 02912-9002&lt;br/&gt;Title: MRI/Dev.: Next-Generation Interactive Virtual-Reality Display Environment for Science &lt;br/&gt;&lt;br/&gt;This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5).&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;&lt;br/&gt; Project Proposed:&lt;br/&gt;This project, developing a world-class interactive large-field-of-view 95 megapixel immersive virtual-reality environment, aims at creating a novel, demonstrably useful, rich, and expressive interaction, visualization, and analysis that truly leverage the human visual and motor systems in Virtual Reality (VR).&lt;br/&gt;This work intends to help accelerate scientific work, research into innovative visualization methods for accelerating science in the future, and even leverage the fundamental advantages of immersive large-field-of-view visualization and body-centric human-computer interaction. Two decades of research have established the value of immersive displays as a research tool in many scientific domains and has also identified a set of currently unmet needs that block application of such displays to new problems and domains. These needs encompass high display resolution, brightness, contrast, and size; fast, responsive tracking with high accuracy and low latency; ease of use in working with new kinds of data; and reliability. Although a few multi-million dollar systems exist that may be able to address these needs, these few systems do not match the proposed display?s color gamut, small physical space requirement, and lower replication cost. The system is expected to support more natural and effective interaction with data than the current 3D point-and-click wand driven CAVEsTM by maximally utilizing as appropriate full-body, motion-captured user interactions and gestures. More display information will be made accessible to the human visual system with less user effort by matching, or exceeding the perceptual qualities of a modern LCD monitor. An immersive stereo display will be integrated with the perceptual resolution of a desktop display and superior brightness and contrast. Integration of software tools for creating virtual-reality applications quickly will address ease-of-use and reliability. The new tools are expected to be simple, support a spectrum of displays, and provide rich support for gestural interaction. A monitoring process to identify potential problems among the interacting hardware and software components will be put in place to identify and address problems before instruments are delayed. Users of the system include planetary geologists, systems biologists, brain scientists, cell and molecular biologists, biologists studying animal motion (including flight), fluid dynamicists, bioengineers studying arterial hemodynamics, visual designers developing interactive techniques for scientists, digital literary artists, and visualization and interaction researchers. Within interaction research, experiments using the system are expected to establish the appropriate level of display technology (e.g., resolution, interactivity, or stereographic display) needed for different classes of scientific analysis. The techniques, monitoring system, and software environment will be distributed on SourceForge to respectively help accelerate scientific progress nationwide, for developing multi-display applications, and for ensuring reliability.&lt;br/&gt;&lt;br/&gt;Broader Impacts: While educating many students, the instrument is expected to enable new advances in all of the scientific disciplines of the users listed above, including a better understanding of the workings of cells and genes and proteins they contain (which could consequently improve quality of life broadly), behavior of fluids in arteries and around moving animals, animal locomotion (which could lead to improved biomimetic locomotive, floating, or flying vehicles), the wiring of the human brain, how it affects human capabilities, and how it can degrade; and Mars. The efforts are likely to produce a new generation of scientists who can better analyze research problems using scientific visualization, computer scientists more cognizant of scientists? analytical needs, and artists and designers who can accelerate the design process for immersive scientific visualization tools.</AbstractNarration>
    <MinAmdLetterDate>08/19/2009</MinAmdLetterDate>
    <MaxAmdLetterDate>03/05/2014</MaxAmdLetterDate>
    <ARRAAmount>1999983</ARRAAmount>
    <AwardID>0923393</AwardID>
    <Investigator>
      <FirstName>David</FirstName>
      <LastName>Laidlaw</LastName>
      <EmailAddress>dhl@cs.brown.edu</EmailAddress>
      <StartDate>08/19/2009</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Andries</FirstName>
      <LastName>van Dam</LastName>
      <EmailAddress>avd@cs.brown.edu</EmailAddress>
      <StartDate>08/19/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>George</FirstName>
      <LastName>Karniadakis</LastName>
      <EmailAddress>George_Karniadakis@brown.edu</EmailAddress>
      <StartDate>08/19/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Jan</FirstName>
      <LastName>Hesthaven</LastName>
      <EmailAddress>Jan_Hesthaven@Brown.edu</EmailAddress>
      <StartDate>08/19/2009</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Brown University</Name>
      <CityName>Providence</CityName>
      <ZipCode>029129002</ZipCode>
      <PhoneNumber>4018632777</PhoneNumber>
      <StreetAddress>BOX 1929</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Rhode Island</StateName>
      <StateCode>RI</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000912</Code>
      <Name>Computer Science</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>1189</Code>
      <Text>MAJOR RESEARCH INSTRUMENTATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1189</Code>
      <Text>MAJOR RESEARCH INSTRUMENTATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9218</Code>
      <Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>HPCC</Code>
      <Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>6890</Code>
      <Text>RECOVERY ACT ACTION</Text>
    </ProgramReference>
  </Award>
</rootTag>
