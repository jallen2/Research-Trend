<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase II: Emotionally Immersive Tele-Learning</AwardTitle>
    <AwardEffectiveDate>08/15/2014</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2017</AwardExpirationDate>
    <AwardAmount>1048057</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Glenn H. Larsen</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This SBIR Phase II project aims to incorporate novel machine vision and social networking functionality into technologies used in online education and webinars. Researchers have long identified engagement as the key ingredient for success in any learning environment and particularly the online environment, but current online teaching systems lack the means by which instructors can gauge their students' level of engagement because these students are not visible. Therefore in order to improve current online teaching modalities, it is necessary to find ways to communicate to the instructor the level of engagement of their unseen online students. The successful outcome of the project will allow the lecturer to receive real-time feedback from facial expressions, gaze and other body kinesics, which when averaged across the virtual classroom, provides feedback related to the reception of information delivery. The project supports NSF's mission in education, which seeks to answer questions about how teachers can provide effective cognitive and motivational support for students. This project aims to promote richer interactions between tutor and online students through integrated cognitive and motivational scaffolding, leading to higher levels of student success enabling them to compete more effectively as skilled artisans in the 21st century workforce. &lt;br/&gt;&lt;br/&gt;&lt;br/&gt;This project contributes four significant innovations: a machine-vision recognition system for gaze direction and facial expressions of engagement, which aggregates data across participants to improve signal to noise; a machine-vision recognition system for detecting hand gestures and postural kinesics; enabling third party pedagogical applications within a framework using ancillary hardware, and which can be sold through an educational application store; and to integrate social network functionality that replicates pre- and post-lecture socialization including pair sharing, breakout groups, team teaching, and support for online teaching assistance. The goals and scope of research required to support the above innovations include: improving machine-vision classifier data and functionality; optimization of user interface and integrated user calibration process; extending the system's functionality to both synchronous and asynchronous modalities; developing neuro-psychological and cognitive models of the online pedagogical process; design and integration of content/media interoperability and social networking capabilities; creation of open application programming interfaces for third-party developers and application store functionality with digital whiteboards and tablets; development of ancillary software modules to help students manage data related to their educational efforts, diagnose study and achievement patterns, and provide expert advice based on that data.</AbstractNarration>
    <MinAmdLetterDate>08/03/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>01/27/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1431024</AwardID>
    <Investigator>
      <FirstName>Ian</FirstName>
      <LastName>Bennett</LastName>
      <EmailAddress>ianmbennettc2y@gmail.com</EmailAddress>
      <StartDate>08/03/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>The Spirituality Network, Inc.</Name>
      <CityName>Palo Alto</CityName>
      <ZipCode>943033222</ZipCode>
      <PhoneNumber>6507969517</PhoneNumber>
      <StreetAddress>2275 East Bayshore Road</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>5373</Code>
      <Text>SMALL BUSINESS PHASE II</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>168E</Code>
      <Text>SBIR/STTR/ERC Collab (SECO)</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>169E</Code>
      <Text>SBIR Tech Enhan Partner (TECP)</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>5373</Code>
      <Text>SMALL BUSINESS PHASE II</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8031</Code>
      <Text>Education Products</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8033</Code>
      <Text>Hardware Software Integration</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8039</Code>
      <Text>Information, Communication &amp; Computing</Text>
    </ProgramReference>
  </Award>
</rootTag>
