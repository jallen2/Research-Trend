<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CAREER: Statistical Analysis of Massive Data Sets under Low-Complexity Constraints</AwardTitle>
    <AwardEffectiveDate>06/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>05/31/2020</AwardExpirationDate>
    <AwardAmount>151694</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gabor J. Szekely</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The development of methods of statistical inference for massive data sets has become a focal point of research in statistics and machine learning in recent years with the dramatic increase of collected data in a wide range of applications such as meteorology, genomics, or finance. A common denominator of these new data sets is that they satisfy certain low-complexity structure conditions. In specific settings, this could mean, for instance, sparsity of a vector in high-dimensional regression or low-rank properties of a high-dimensional matrix. This research aims at providing new efficient solutions exploiting these particular structures in order to perform accurate inference. The future findings should be of interest to a broad audience in the data science community. The investigator also intends to integrate his contributions into educational activities such as course development and mentoring of undergraduate and graduate students.&lt;br/&gt;&lt;br/&gt;The research objectives of this project are to identify new informative low-complexity structures in large scale data sets and propose new methods that are adaptive to these structures, computationally efficient, and statistically optimal in a variety of models, including in particular vector regression, trace regression, principal component analysis for standard and functional data. The new procedures will be based on penalized empirical risk minimization and exponential weights mixing that favor low-complexity solutions. The investigator plains to (a) determine fundamental characteristics of the problems that govern the performance of these procedures; (b) establish new oracle inequalities results in high dimension to assess the statistical performances of these procedures; (c) investigate the computational performance of these procedures under various conditions on the models.</AbstractNarration>
    <MinAmdLetterDate>02/12/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>02/25/2016</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1454515</AwardID>
    <Investigator>
      <FirstName>Karim</FirstName>
      <LastName>Lounici</LastName>
      <EmailAddress>klounici6@math.gatech.edu</EmailAddress>
      <StartDate>02/12/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1269</Code>
      <Text>STATISTICS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>8048</Code>
      <Text>Division Co-Funding: CAREER</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1045</Code>
      <Text>CAREER: FACULTY EARLY CAR DEV</Text>
    </ProgramReference>
  </Award>
</rootTag>
