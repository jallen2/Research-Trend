<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Obtaining Unbiased Math and Science Achievement Effect Estimates from Nonrandomized Studies</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>233660</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11010000</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Graduate Education</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Finbarr Sloane</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The researchers in this project will use large longitudinal datasets that include rich arrays of descriptive variables as well as measures of science and mathematics achievement to identify promising covariates that may eliminate or greatly reduce selection bias in nonrandomized estimates of program effects in research and evaluations of interventions or programs for K-12 students. Simulated nonrandomized intervention and comparison groups with selection bias will be created from a selection of data from five de-identified, publically available longitudinal datasets. The researchers will then create propensity scores for each simulation based on the examination of the magnitude of the multiple correlations between covariates and the outcome and use these scores to assess how much of the selection bias they might eliminate. The identification of covariates that sufficiently account for enough selection bias so that the remaining selection bias might be ignored will strengthen the use of quasi-experimental study design in STEM education.&lt;br/&gt;&lt;br/&gt;Randomized control designs in STEM education are well known as being the strongest causal design with the ability to provide unbiased estimates of the effects of programs or interventions on intended outcomes. With an adequate sample size to minimize the likelihood of chance differences, random assignment can be expected to equate the experimental groups on all baseline characteristics that might influence the outcomes of interest. However, randomized experiments are not always possible in situations where the effects of STEM education programs are of interest. For many practical and occasionally, ethical reasons, nonrandomized comparison group designs are frequently used in STEM education research and evaluation studies. The findings of this study will provide empirical evidence of what covariate data should be collected to reduce selection bias in quasi-experimental designs.</AbstractNarration>
    <MinAmdLetterDate>08/05/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>08/05/2014</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1438331</AwardID>
    <Investigator>
      <FirstName>Mark</FirstName>
      <LastName>Lipsey</LastName>
      <EmailAddress>mark.lipsey@vanderbilt.edu</EmailAddress>
      <StartDate>08/05/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Kimberly</FirstName>
      <LastName>Nesbitt</LastName>
      <EmailAddress>kimberly.nesbitt@vanderbilt.edu</EmailAddress>
      <StartDate>08/05/2014</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Vanderbilt University</Name>
      <CityName>Nashville</CityName>
      <ZipCode>372350002</ZipCode>
      <PhoneNumber>6153222631</PhoneNumber>
      <StreetAddress>Sponsored Programs Administratio</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Tennessee</StateName>
      <StateCode>TN</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7261</Code>
      <Text>PROGRAM EVALUATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
  </Award>
</rootTag>
