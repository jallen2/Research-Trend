<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CHS: Small: Non-visual Access to Graphical Information Using a Vibro-Audio Display</AwardTitle>
    <AwardEffectiveDate>09/01/2014</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>515213</AwardAmount>
    <AwardInstrument>
      <Value>Continuing grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Ephraim P. Glinert</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Vision impairment is estimated by the World Health Organization as effecting 12 million people in the United States and as many as 285 million people worldwide, and these numbers are projected to double by 2030 due to the aging of our population. Lack of access to non-textual material such as graphs and maps is a major impediment for the blind, because the ability to apprehend and accurately interpret such information is critical for success in the classroom and in the workplace, as well as for independent travel. The inability to exploit this information helps explain why only about 11% of blind or low-vision persons have a bachelor's degree, why only 25% of blind people are employed, and why almost 70% of blind individuals do not navigate independently outside of their home. A major step toward improving these numbers, as well as the overall quality of life for members of the blind and low-vision community, would be to solve the longstanding challenge of affording low-cost and effective access to key graphical material.&lt;br/&gt;&lt;br/&gt;The PI's goal in this project is to develop and evaluate a highly intuitive tool for doing just that. To this end, he will explore a multimodal combination of vibro-tactile, audio, and kinesthetic cues that can be generated by modern touchscreen tablets (especially smartphones), to convey useful visual information in real-time. Benefits of this approach include portability, affordability, and flexibility of use for multiple critical and common applications such as those enumerated above. The PI argues that considering these design factors from the outset, in conjunction with principled empirical investigations to evaluate and enhance information perceptibility interleaved with frequent prototype testing and iterative refinement, with tight involvement of members of the target population in all phases of the research, will ensure that project outcomes significantly reduce the graphical information gap between blind persons and their sighted peers. The research will make important contributions to our understanding of how blind and low-vision individuals process non-visual information, which is essential for rendering perceptually salient multimodal graphics, and will also help establish best practices both for rendering these graphics using a vibro-audio interface implemented on touchscreen enabled devices, as well as for similar future specialized interface development efforts.</AbstractNarration>
    <MinAmdLetterDate>07/31/2014</MinAmdLetterDate>
    <MaxAmdLetterDate>07/28/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1425337</AwardID>
    <Investigator>
      <FirstName>Nicholas</FirstName>
      <LastName>Giudice</LastName>
      <EmailAddress>nicholas.giudice@maine.edu</EmailAddress>
      <StartDate>07/31/2014</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Maine</Name>
      <CityName>ORONO</CityName>
      <ZipCode>044695717</ZipCode>
      <PhoneNumber>2075811484</PhoneNumber>
      <StreetAddress>5717 Corbett Hall</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Maine</StateName>
      <StateCode>ME</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7367</Code>
      <Text>Cyber-Human Systems (CHS)</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7367</Code>
      <Text>Cyber-Human Systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9150</Code>
      <Text>EXP PROG TO STIM COMP RES</Text>
    </ProgramReference>
  </Award>
</rootTag>
