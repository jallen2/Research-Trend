<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>CDI-Type I: Understanding Regulation of Visual Attention in Autism through Computational and Robotic Modeling</AwardTitle>
    <AwardEffectiveDate>10/01/2008</AwardEffectiveDate>
    <AwardExpirationDate>03/31/2012</AwardExpirationDate>
    <AwardAmount>700000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04050000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Divn Of Social and Economic Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Cheryl L. Eavey</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Eye tracking has become a widespread tool throughout the cognitive sciences and has attracted particular attention as a behavioral measurement tool for children with developmental disabilities. However, there are no standardized quantitative tools for assessing broadly defined attention skills in young children, and there is a lack of analysis techniques that would allow gaze patterns to be compared across individuals, across populations, or for a single individual across time. This study will develop methods of quantitatively measuring attentional capacities by (1) designing a Visual Attention Assessment Suite (VAAS) which examines the interaction and impact of particular features of scenes on visual attention; (2) constructing novel computational analysis techniques for comparing gaze patterns across individuals, populations, and time; (3) validating these techniques against both standard behavioral assessment protocols and through an embodied modeling approach to ensure that our models capture the behaviorally important aspects of gaze. &lt;br/&gt;&lt;br/&gt;The regulation of attention has been hypothesized as one of the fundamental factors affecting early development of children with autism. This project will develop quantitative measures that can be used as diagnostic and prognostic indicators and to evaluate the effectiveness of particular treatment approaches. This project represents the first integrated and interdisciplinary attempt to develop a much needed full-scale diagnostic instrument that operates purely through eye-tracking, computational techniques, and individual modeling. Although our primary focus is the interpretation of gaze data with respect to autism, eye tracking is used extensively in psychology, primatology, usability studies, marketing, and human-computer interaction experiments. The models and analysis tools constructed under this project will be equally applicable to these other domains. This project also has the potential to produce novel methods of assessing attentional abnormalities in other developmental disorders (e.g., mental retardation, attention deficit disorder, specific learning disabilities), novel educational assessment methods of pre-kindergarten readiness, as well as to develop training methods for teaching clinicians and educators behavioral assessment using a robot as a model illustrating various attentional patterns in children with disabilities.</AbstractNarration>
    <MinAmdLetterDate>09/22/2008</MinAmdLetterDate>
    <MaxAmdLetterDate>09/22/2008</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>0835767</AwardID>
    <Investigator>
      <FirstName>Brian</FirstName>
      <LastName>Scassellati</LastName>
      <EmailAddress>brian.scassellati@yale.edu</EmailAddress>
      <StartDate>09/22/2008</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Katarzyna</FirstName>
      <LastName>Chawarska</LastName>
      <EmailAddress>katarzyna.chawarska@yale.edu</EmailAddress>
      <StartDate>09/22/2008</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Yale University</Name>
      <CityName>New Haven</CityName>
      <ZipCode>065208327</ZipCode>
      <PhoneNumber>2037854689</PhoneNumber>
      <StreetAddress>Office of Sponsored Projects</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Connecticut</StateName>
      <StateCode>CT</StateCode>
    </Institution>
    <FoaInformation>
      <Code>0000099</Code>
      <Name>Other Applications NEC</Name>
    </FoaInformation>
    <FoaInformation>
      <Code>0116000</Code>
      <Name>Human Subjects</Name>
    </FoaInformation>
    <ProgramElement>
      <Code>7750</Code>
      <Text>CDI TYPE I</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>0000</Code>
      <Text>UNASSIGNED</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7722</Code>
      <Text>COMPLEXITY</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>OTHR</Code>
      <Text>OTHER RESEARCH OR EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
