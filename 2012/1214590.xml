<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SBIR Phase I: Hybrid Human-Machine Vision System for Convenient and Accurate Image Annotation</AwardTitle>
    <AwardEffectiveDate>07/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2012</AwardExpirationDate>
    <AwardAmount>0</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Glenn H. Larsen</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This Small Business Innovation Research Phase I project aims to investigate the viability of a system for image annotation via a combination of machine vision and crowd-sourcing. Annotating a large body of images quickly, accurately and inexpensively would be a valuable capability in scientific, medical and other commercial applications. Examples include: medical diagnosis (e.g. trace the vasculature in a slice of cancerous tissue), neuroscience (e.g. count and locate all cells marked with a given antibody), and urban planning (e.g. count all houses that have private pools in a neighborhood). Machine vision is making progress towards delivering such capabilities. However, accuracy is not yet sufficient for many applications. In recent years a complementary solution has become available: crowdsourcing, that is, dynamically recruiting thousands of people to carry out an assigned task from their home computer. Our research (at Caltech and UC San Diego) suggests that it is possible to combine the complementary strengths of human annotators and machines into a hybrid system that is flexible, accurate, fast and inexpensive. We will build a prototype to test this hypothesis.&lt;br/&gt;&lt;br/&gt;The broader impact/commercial potential of this project affects a wide array of domains and applications. As imaging becomes more available and storage inexpensive, the amount of image data will continue to increase. This is true for the scientific research market (e.g. the advent of high-throughput microscopes and automated telescopes), the geospatial information systems market (e.g. the advent of commercially operated satellites with on-board imaging systems), and the consumer market (e.g. the advent of smart phones with cameras). The proposed venture will fill the need to scale annotation and analysis of this data, and keeping this process as inexpensive and fast as possible. By combining computer vision and machine learning automation with humans, both experts and non-expert annotators, our system will be quickly configurable and trainable by the users to address virtually any image analysis challenge. Easy, accurate and inexpensive image analysis will revolutionize many areas of scientific research and commerce.</AbstractNarration>
    <MinAmdLetterDate>06/19/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>09/26/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1214590</AwardID>
    <Investigator>
      <FirstName>Boris</FirstName>
      <LastName>Babenko</LastName>
      <EmailAddress>bbabenko@gmail.com</EmailAddress>
      <StartDate>06/19/2012</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Anchovi Labs, Inc</Name>
      <CityName>Menlo Park</CityName>
      <ZipCode>940250000</ZipCode>
      <PhoneNumber>9494636033</PhoneNumber>
      <StreetAddress>2420 Sand Hill Road, Suite 300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>5371</Code>
      <Text>SMALL BUSINESS PHASE I</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>5371</Code>
      <Text>SMALL BUSINESS PHASE I</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8033</Code>
      <Text>Hardware Software Integration</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8040</Code>
      <Text>Energy and Environment</Text>
    </ProgramReference>
  </Award>
</rootTag>
