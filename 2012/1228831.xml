<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Nimble Assessments: Tools for the Design and Analysis of Interactive Assessments</AwardTitle>
    <AwardEffectiveDate>10/01/2012</AwardEffectiveDate>
    <AwardExpirationDate>09/30/2015</AwardExpirationDate>
    <AwardAmount>799999</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>11090000</Code>
      <Directorate>
        <LongName>Direct For Education and Human Resources</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Research On Learning</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Connie K. Della-Piana</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This full-scale project is developing and adapting innovative methodologies and tools to facilitate the design of interactive assessments of student learning processes that are mediated by technology. Building on previous work, the project incorporates three components and capabilities into an existing platform that makes it suitable for implementation in a wide range of learning environments. The components are authoring tools, crowd-sourcing resources, and automated support for data abstraction.&lt;br/&gt;&lt;br/&gt;A team of researchers and developers from Stanford University lead the effort and are developing the following products (1) an authoring language to develop interactive assessments of student learning; (2) a crowd sourcing dashboard to facilitate validation of measures; and (3) a data abstraction platform to assist in the collection and analysis of the rich corpus of data associated with these types of assessments.&lt;br/&gt;&lt;br/&gt;With an increased interest in the development and use of a wide range of ways to assess student learning, this full scale research and development project focuses on the development of an assessment infrastructure that supports the creation and use of new forms of assessments and analyses. The main platform is designed to support subsequent extensions and feature addition in response to the dynamic nature of knowledge about student learning and new approaches to measuring student outcomes.</AbstractNarration>
    <MinAmdLetterDate>09/24/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>09/24/2012</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1228831</AwardID>
    <Investigator>
      <FirstName>Daniel</FirstName>
      <LastName>Schwartz</LastName>
      <EmailAddress>daniel.schwartz@stanford.edu</EmailAddress>
      <StartDate>09/24/2012</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Stanford University</Name>
      <CityName>Palo Alto</CityName>
      <ZipCode>943041212</ZipCode>
      <PhoneNumber>6507232300</PhoneNumber>
      <StreetAddress>3160 Porter Drive</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7261</Code>
      <Text>PROGRAM EVALUATION</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9177</Code>
      <Text>ELEMENTARY/SECONDARY EDUCATION</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>SMET</Code>
      <Text>SCIENCE, MATH, ENG &amp; TECH EDUCATION</Text>
    </ProgramReference>
  </Award>
</rootTag>
