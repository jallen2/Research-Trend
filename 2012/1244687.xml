<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>BCC-SBE: Seeing Speech: Building a Community</AwardTitle>
    <AwardEffectiveDate>09/15/2012</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2016</AwardExpirationDate>
    <AwardAmount>255272</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>John E. Yellen</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Human language integrates several complex systems. Sound is the most accessible of these, with measurable acoustic and articulatory properties, yet it is poorly understood because it involves multiple interacting modalities: lips, velum, tongue, and larynx all conspire to give each sound its unique properties. Understanding how sound works in language is important to basic linguistic and cognitive sciences as well as to applied research such as speech sciences and automatic speech recognition.&lt;br/&gt;&lt;br/&gt;Technological advances make collecting articulatory data relatively trivial, while technology for annotation and analysis lags behind. In response, we are developing (i) a software suite for simultaneous extraction and automatic analysis of articulatory speech data (UltraPraat), integrated seamlessly with the premier software for acoustic analysis of speech (Praat); and (ii), a database coupling articulatory and acoustic speech data (UltraSpeech) to support development and evaluation of theories of acoustic and articulatory phonetics, based on an existing database such as TIMIT.&lt;br/&gt;&lt;br/&gt;The success of such a venture depends on both the quality of execution and on how well it is received by the community. The goal of this project is to determine the key properties for both software and database that, if developed, would be most beneficial to the community of users. This project will create a prototype of the analytic software, develop the community of potential users, and refine software and database specifications to best meet the community's needs. The outcomes will be a working prototype, a community of researchers who understand its benefits, and a set of specifications for the infrastructure.&lt;br/&gt;&lt;br/&gt;This project brings together language researchers with a wide range of interests in human articulation. The discussions will ensure that the infrastructure developed to fill the current gap in articulatory data and analysis software will provide as much benefit as possible to all the related fields in technology and the sciences; they may also give rise to new research synergies. The prototype will be made available publicly, so others may begin using the results of this project for research, even before the full model is complete. UltraPraat and UltraSpeech have the potential for transforming research in all domains of oral tract articulation, such as the diversity of human language sounds, language acquisition and endangered languages, speech deficits, foreign language pronunciation, oral language for the profoundly deaf, speech recognition and synthesis software, and how musicians shape sounds while playing wind instruments.</AbstractNarration>
    <MinAmdLetterDate>09/25/2012</MinAmdLetterDate>
    <MaxAmdLetterDate>01/15/2013</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1244687</AwardID>
    <Investigator>
      <FirstName>Diana</FirstName>
      <LastName>Archangeli</LastName>
      <EmailAddress>dba@email.arizona.edu</EmailAddress>
      <StartDate>09/25/2012</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Arizona</Name>
      <CityName>Tucson</CityName>
      <ZipCode>857194824</ZipCode>
      <PhoneNumber>5206266000</PhoneNumber>
      <StreetAddress>888 N Euclid Ave</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Arizona</StateName>
      <StateCode>AZ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8068</Code>
      <Text>Data Infrastructure</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7433</Code>
      <Text>CyberInfra Frmwrk 21st (CIF21)</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9179</Code>
      <Text>GRADUATE INVOLVEMENT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9251</Code>
      <Text>RES EXPER FOR UNDERGRAD-SUPPLT</Text>
    </ProgramReference>
  </Award>
</rootTag>
