<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER: Mining a Year of Speech</AwardTitle>
    <AwardEffectiveDate>08/15/2010</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2012</AwardExpirationDate>
    <AwardAmount>99899</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05020000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Information &amp; Intelligent Systems</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tatiana D. Korelsky</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Technologies for storing and processing vast amounts of text are mature and well-defined. In contrast, technologies for browsing or mining content from large collections of non-textual material, especially audio and video, are less well developed. Large sale data mining on text has helped transform the relevant disciplines; the disciplines dealing with spoken language will reap similar benefits from accessible, searchable, large corpora.&lt;br/&gt;&lt;br/&gt;This project explores the difficult problem of providing rich, intelligent data mining capabilities for a substantial collection of spoken audio data in American and British English. It applies and extends state-of-the-art techniques to offer sophisticated, rapid and flexible access to a richly annotated corpus of a year of speech (about 9,000 hours, 100 million words, or 2 terabytes), derived from the Linguistic Data Consortium, the British National Corpus, and other existing resources. This is ten times more data than has previously been used by researchers in fields such as phonetics, linguistics, and psychology, and 100 to 1,000 times the amounts that are used in common practice.&lt;br/&gt;&lt;br/&gt;Speech-to-text alignment and search tools will open a new universe of data to researchers in many fields, from linguistics and phonetics to anthropology, speech communication, oral history, and media studies. Audio-video usage on the internet is large and growing at an extraordinary rate, offering increasingly large amounts of an increasingly large range of material. Reliable automatic annotation, indexing and search of this material will allow researchers to examine the distribution of both form and content across time, space, and social structure.</AbstractNarration>
    <MinAmdLetterDate>08/08/2010</MinAmdLetterDate>
    <MaxAmdLetterDate>08/08/2010</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1048900</AwardID>
    <Investigator>
      <FirstName>Jiahong</FirstName>
      <LastName>Yuan</LastName>
      <EmailAddress>jiahong@ling.upenn.edu</EmailAddress>
      <StartDate>08/08/2010</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Mark</FirstName>
      <LastName>Liberman</LastName>
      <EmailAddress>myl@unagi.cis.upenn.edu</EmailAddress>
      <StartDate>08/08/2010</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Christopher</FirstName>
      <LastName>Cieri</LastName>
      <EmailAddress>ccieri@ldc.upenn.edu</EmailAddress>
      <StartDate>08/08/2010</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Pennsylvania</Name>
      <CityName>Philadelphia</CityName>
      <ZipCode>191046205</ZipCode>
      <PhoneNumber>2158987293</PhoneNumber>
      <StreetAddress>Research Services</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Pennsylvania</StateName>
      <StateCode>PA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7495</Code>
      <Text>ROBUST INTELLIGENCE</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
  </Award>
</rootTag>
