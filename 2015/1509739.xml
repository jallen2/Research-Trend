<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Asymptotics and concentration in spectral estimation for large matrices</AwardTitle>
    <AwardEffectiveDate>07/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2018</AwardExpirationDate>
    <AwardAmount>289425</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Gabor J. Szekely</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Estimation of large matrices and their spectral characteristics is crucial in a variety of problems of science and engineering that deal with large high-dimensional data sets. Spectral methods are of the utmost importance in kernel machine learning, manifold learning, functional data analysis, community detection in large networks, quantum statistics and quantum information, and many other applications. The purpose of the project is to develop new mathematical tools needed in analysis of high-dimensional and infinite-dimensional matrix estimation problems that could potentially lead to more powerful methods of statistical inference for complex, high-dimensional data. The project also includes a number of activities with an impact on graduate education and on research collaborations between statistics, computer science and other areas.&lt;br/&gt;&lt;br/&gt;The focus of the project is on concentration properties and asymptotics of spectral characteristics (eigenvalues, eigenvectors, spectral projectors) of several important classes of random matrices and operators playing crucial role in high dimensional and infinite dimensional statistical inference and in machine learning. They include sample covariance operators, kernel matrices in machine learning, empirical heat kernels and Laplacians for manifold data, matrices involved in spectral clustering problems on graphs, matrix estimators in trace regression problems (such as matrix completion and quantum state tomography). The main goal is to study the problems where there exists an operator norm consistent estimator of the target matrix (operator), but it converges at a slow rate and to develop a broad range of concentration bounds and asymptotic results for specific functionals of the underlying random matrix (operator) such as its eigenvalues, bilinear forms of its spectral projection operators, norms of deviations of empirical spectral projection operators from their true counterparts. The solution of these problems relies on further development of the methods of high-dimensional probability, such as concentration inequalities, generic chaining bounds for Gaussian, empirical and related classes of stochastic processes, non-asymptotic bounds for random matrices.</AbstractNarration>
    <MinAmdLetterDate>06/19/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>06/19/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1509739</AwardID>
    <Investigator>
      <FirstName>Vladimir</FirstName>
      <LastName>Koltchinskii</LastName>
      <EmailAddress>vlad@math.gatech.edu</EmailAddress>
      <StartDate>06/19/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Georgia Tech Research Corporation</Name>
      <CityName>Atlanta</CityName>
      <ZipCode>303320420</ZipCode>
      <PhoneNumber>4048944819</PhoneNumber>
      <StreetAddress>Office of Sponsored Programs</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Georgia</StateName>
      <StateCode>GA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1269</Code>
      <Text>STATISTICS</Text>
    </ProgramElement>
  </Award>
</rootTag>
