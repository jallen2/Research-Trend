<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>EAGER/Collaborative Research: A New Science of Visual Experience</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>195845</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07030000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Diwakar Gupta</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The essence of human experience is interacting with the natural and man-made environments through the five human senses, and through vision in particular. The objective of this EArly-concept Grant for Exploratory Research (EAGER) project is to build analytical foundations for a new science of visual experience that will bridge basic approaches from cognitive science and systems engineering. Specifically, the research will build mathematical and computational models of a human navigating a three dimensional space such as a factory, museum, or retail store. The idea is to gain insights into the limits on observability and controllability in human-technology systems, and to improve the user's situational awareness. If the research is successful, researchers will be able to describe situations in terms of possibilities for action and access to information. Such quantitative tools will allow engineers to design environments to achieve outcomes such as increased focus, improved safety, better wayfinding, and improved experience. In time, it might be possible to engineer interactive environments that adapt to the personal attributes and identities of the humans that inhabit them. The results of the research have the potential to be used by many disciplines such as engineering, business, architecture, psychology, cognition, and human factors.&lt;br/&gt;&lt;br/&gt;The multidisciplinary research team consisting of academics (engineering, psychology, and computer science) and two industry personnel suggests moving visual experience of a three dimensional environment from the realm of intuition and experience to analytical science. The specific focus of this grant will be on developing a general set of analytical models that emerge from the analysis of a variety of context-specific human-environment interactions (e.g., nurse in CCU, shopper in a retail store). With a solid grounding in the basic psychology of Perception-Action, the analytical models will integrate three-dimensional spatial relationships with the human eye's field of vision and the physical attributes of a human. Most significantly, the research will consider complex dynamics resulting from human movement in the space, with all the attendant changes in visual angles, and the appearance and disappearance of visual obstacles. Human performance will be empirically examined in a Virtual Environment in order to validate the analytical metrics of visual experience.</AbstractNarration>
    <MinAmdLetterDate>09/04/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>09/13/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1548394</AwardID>
    <Investigator>
      <FirstName>John</FirstName>
      <LastName>Flach</LastName>
      <EmailAddress>john.flach@wright.edu</EmailAddress>
      <StartDate>09/11/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>James</FirstName>
      <LastName>Munch</LastName>
      <EmailAddress>james.munch@wright.edu</EmailAddress>
      <StartDate>09/04/2015</StartDate>
      <EndDate>09/11/2015</EndDate>
      <RoleCode>Former Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Thomas</FirstName>
      <LastName>Wischgoll</LastName>
      <EmailAddress>thomas.wischgoll@wright.edu</EmailAddress>
      <StartDate>09/04/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Pratik</FirstName>
      <LastName>Parikh</LastName>
      <EmailAddress>pratik.parikh@wright.edu</EmailAddress>
      <StartDate>09/04/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Jennie</FirstName>
      <LastName>Gallimore</LastName>
      <EmailAddress>jgalli@cs.wright.edu</EmailAddress>
      <StartDate>09/04/2015</StartDate>
      <EndDate>09/11/2015</EndDate>
      <RoleCode>Former Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Wright State University</Name>
      <CityName>Dayton</CityName>
      <ZipCode>454350001</ZipCode>
      <PhoneNumber>9377752425</PhoneNumber>
      <StreetAddress>3640 Colonel Glenn Highway</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Ohio</StateName>
      <StateCode>OH</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7633</Code>
      <Text>EFRI RESEARCH PROJECTS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>030E</Code>
      <Text>CONTROL SYSTEMS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>031E</Code>
      <Text>MECHATRONICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>032E</Code>
      <Text>SENSORS AND ACTUATORS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>033E</Code>
      <Text>Smart and responsive structures</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>034E</Code>
      <Text>Dynamical systems</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7916</Code>
      <Text>EAGER</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8025</Code>
      <Text>Advanced Materials Processing</Text>
    </ProgramReference>
  </Award>
</rootTag>
