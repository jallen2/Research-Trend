<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>I-Corps: Turning a Mobile Device into a Mouse in the Air</AwardTitle>
    <AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>12/31/2016</AwardExpirationDate>
    <AwardAmount>50000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>07070000</Code>
      <Directorate>
        <LongName>Directorate For Engineering</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Industrial Innovation &amp; Partnersh</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Lydia Mcclure</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>A mouse has been one of the most successful technologies for controlling the graphic user interface due to its ease of use. Its attraction penetrates well beyond just computers. There already have been mice designed for game consoles and smart TVs. A smart TV allows a user to run popular computer programs and smartphone applications. For example, a smart TV user may want to use a Web browser and click on a certain URL or some part of a map using a mouse. A traditional remote controller, which uses buttons for user input, is no longer sufficient to exploit full functionalities offered by the smart TV. More and more devices in the future, such as Google Glasses, baby monitors, and a new generation of home appliances, all desire mouse functionalities, which allow users to choose from a wide variety of options and easily click on different parts of the view. On the other hand, a traditional mouse, which requires a flat, smooth surface to operate, cannot satisfy many new usage scenarios. This I-Corps team has developed an accurate and easy way of tracking hand movement, and believes this technology has a wide range of potential applications in smart glasses and the Internet of Things.&lt;br/&gt;&lt;br/&gt;This team has developed an Air Mouse that accurately tracks device movement in real time. It enables any mobile device with a microphone, such as a smart phone and smart watch, to serve as a mouse to control an electronic device with speakers. A unique feature of the proposed approach is that it achieves high tracking accuracy using existing hardware in mobile and electronic devices. Applications of the proposed technology include controlling smart TVs, smart glasses, and home appliances. The proposed approach sends inaudible sound pulses at a few selected frequencies, and uses the frequency shifts to estimate the speed and distance traveled. Techniques have also been developed to quickly calibrate the distance between speakers and narrow down the device's initial position using its movement trajectory. Based on the information, the device's new position in real time can be continuously tracked.</AbstractNarration>
    <MinAmdLetterDate>07/03/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>07/03/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1546831</AwardID>
    <Investigator>
      <FirstName>Lili</FirstName>
      <LastName>Qiu</LastName>
      <EmailAddress>lili@cs.utexas.edu</EmailAddress>
      <StartDate>07/03/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Texas at Austin</Name>
      <CityName>Austin</CityName>
      <ZipCode>787121532</ZipCode>
      <PhoneNumber>5124716424</PhoneNumber>
      <StreetAddress>101 E. 27th Street, Suite 5.300</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Texas</StateName>
      <StateCode>TX</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8023</Code>
      <Text>I-Corps</Text>
    </ProgramElement>
  </Award>
</rootTag>
