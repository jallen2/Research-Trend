<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>SHF: Small: Bio-inspired ultra-broadband RF scene analysis</AwardTitle>
    <AwardEffectiveDate>07/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>06/30/2018</AwardExpirationDate>
    <AwardAmount>439733</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Sankar Basu</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>The detection and analysis of structured signals in noisy and cluttered environments is a fundamental problem in areas ranging from radio communications to image processing and speech recognition. Biological sensory systems have been optimized by millions of years of evolution to solve this problem with exquisite precision and efficiency; man-made communication and signal processing systems do not achieve anywhere near the same level of performance or even share similar fundamental design principles. This project will try to bridge this gap by understanding the universal information processing principles used by the auditory system to analyze natural sounds, and then adapting them to analyze man-made radio frequency (RF) signals. In particular, it will focus on developing electronics and algorithms that emulate some of the amazing capabilities of the biological cochlea (inner ear) and auditory pathway. Graduate and undergraduate students including members of underrepresented groups will be trained as part of this research, thus enlarging the technologically trained workforce of the future.&lt;br/&gt;&lt;br/&gt;The bio-inspired approach of this project was motivated by two observations. Firstly, the process by which the auditory system, beginning with the cochlea, analyzes the fine time-frequency content of sounds is both extremely precise and also highly efficient from an algorithmic viewpoint. Secondly, audio and RF scenes are generated by similar physics (wave propagation, absorption, scattering, diffraction, and interference), even though the relevant velocities and time delays differ by a factor of about a million. Thus audio and RF scenes share many of the same characteristics, which makes it interesting to consider models of cochlear mechanics, signal transduction, and auditory coding that are scaled to operate at much higher frequencies. The first research goal is to build a single-chip cochlear model that analyzes RF signals in the GHz range and encodes frequency, amplitude, and phase information into parallel event-driven outputs that are analogous to auditory nerve fibers. The second goal is to allow higher-level properties, such as source locations and categories, to be efficiently extracted from input signals by developing a robust coding framework to create compressed representations of the cochlear outputs.</AbstractNarration>
    <MinAmdLetterDate>07/08/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>07/08/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1525162</AwardID>
    <Investigator>
      <FirstName>Michael</FirstName>
      <LastName>Lewicki</LastName>
      <EmailAddress>michael.lewicki@case.edu</EmailAddress>
      <StartDate>07/08/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Soumyajit</FirstName>
      <LastName>Mandal</LastName>
      <EmailAddress>sxm833@case.edu</EmailAddress>
      <StartDate>07/08/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Case Western Reserve University</Name>
      <CityName>CLEVELAND</CityName>
      <ZipCode>441064901</ZipCode>
      <PhoneNumber>2163684510</PhoneNumber>
      <StreetAddress>Nord Hall, Suite 615</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Ohio</StateName>
      <StateCode>OH</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7798</Code>
      <Text>SOFTWARE &amp; HARDWARE FOUNDATION</Text>
    </ProgramElement>
    <ProgramElement>
      <Code>8624</Code>
      <Text>IntgStrat Undst Neurl&amp;Cogn Sys</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7923</Code>
      <Text>SMALL PROJECT</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>7945</Code>
      <Text>DES AUTO FOR MICRO &amp; NANO SYST</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8089</Code>
      <Text>Understanding the Brain/Cognitive Scienc</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>8091</Code>
      <Text>BRAIN Initiative Res Support</Text>
    </ProgramReference>
  </Award>
</rootTag>
