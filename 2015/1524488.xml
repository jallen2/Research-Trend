<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Doctoral Dissertation Research: The integration of visual and auditory information in tone perception</AwardTitle>
    <AwardEffectiveDate>08/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>07/31/2017</AwardExpirationDate>
    <AwardAmount>13890</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>04040000</Code>
      <Directorate>
        <LongName>Direct For Social, Behav &amp; Economic Scie</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Behavioral and Cognitive Sci</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Joan Maling</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Languages vary in how they use the pitch of voice to convey meaning. In a tone language, pitch is used to differentiate word meanings. For example, in Mandarin Chinese, the syllable ma said with a steady high tone means 'mother', but said with a falling tone it means 'to scold'. Tone languages represent 60%-70% of the world's 6,000 languages; about 20% of them have tones that sound very similar to each other and are difficult for non-native speakers to distinguish. More and more people around the world are learning tone languages because of globalization, international business, migration, and cross-cultural communications. In the United States, the number of college students studying Chinese alone was over 61,000 as of 2013, and the number is likely to surpass 134,000 by 2050. As the economy of the United States has become increasingly international, the demand for foreign language proficiency is stronger and stronger, and many less commonly taught tone languages such as Vietnamese and Thai have attracted a large number of learners. However, learning a tone language is challenging. Research has shown that, in general, people have difficulties distinguishing and pronouncing tones in a foreign language and that this hinders cross-cultural communication, as miscommunication arises due to mispronunciation. Thus, better learning of tone languages would help the American business community in trade with China and other areas where tone languages are spoken.&lt;br/&gt;&lt;br/&gt;The focus of this project is the process for learning tones in Cantonese, a language with tones that are difficult for non-native speakers to distinguish. Specifically, this project aims to investigate whether non-native speakers can benefit from providing tone marks, a set of symbols to show pitch contour, in learning to distinguish and produce Cantonese tones. The research will be conducted in 3 locations: the United States, Thailand and Hong Kong, where native speakers of American English, Mandarin, Thai, and Cantonese are easily found. In the United States, native speakers of American English and native speakers of Mandarin will participate in a listening-based tone learning experiment to learn to hear and produce the contrasts of Cantonese tones with or without the help of tone marks. Although both Cantonese and Mandarin are varieties of Chinese, they have different tone systems. While Mandarin has four tones (high, mid rising, low-dipping and high falling), Cantonese has six (high, mid, low, high-rising, low-rising and low falling). Studies have shown that Mandarin speakers have difficulties learning Cantonese tones. The same experiment will be conducted in Thailand with native speakers of Thai. Native speakers of Cantonese in Hong Kong will participate in the experiment to provide a comparison case. The investigators will assess whether the addition of tone marks can result in substantial improvement in distinguishing and producing Cantonese tones by the non-native speakers. The investigators will also assess whether people from different language backgrounds exhibit different learning patterns and whether they can achieve native-like results. The findings from this research will provide insight into how foreign language learners integrate visual and auditory information during non-native sound learning. The results will also show how human beings use visual and auditory information in speech processing in general. This study will also have the potential to improve the teaching of tone languages. If tone marks are proven to be helpful, they can easily be included in teaching materials and used as a teaching method for better tone-learning outcomes.</AbstractNarration>
    <MinAmdLetterDate>06/02/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>06/02/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1524488</AwardID>
    <Investigator>
      <FirstName>Natasha</FirstName>
      <LastName>Warner</LastName>
      <EmailAddress>nwarner@u.arizona.edu</EmailAddress>
      <StartDate>06/02/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Yan</FirstName>
      <LastName>Chen</LastName>
      <EmailAddress>yanchen@email.arizona.edu</EmailAddress>
      <StartDate>06/02/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of Arizona</Name>
      <CityName>Tucson</CityName>
      <ZipCode>857194824</ZipCode>
      <PhoneNumber>5206266000</PhoneNumber>
      <StreetAddress>888 N Euclid Ave</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Arizona</StateName>
      <StateCode>AZ</StateCode>
    </Institution>
    <ProgramElement>
      <Code>8374</Code>
      <Text>DDRI Linguistics</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>1311</Code>
      <Text>LINGUISTICS</Text>
    </ProgramReference>
    <ProgramReference>
      <Code>9179</Code>
      <Text>GRADUATE INVOLVEMENT</Text>
    </ProgramReference>
  </Award>
</rootTag>
