<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Theory and Algorithms of Transformed L1 Minimization with Applications in Data Science</AwardTitle>
    <AwardEffectiveDate>09/15/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2018</AwardExpirationDate>
    <AwardAmount>299890</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>03040000</Code>
      <Directorate>
        <LongName>Direct For Mathematical &amp; Physical Scien</LongName>
      </Directorate>
      <Division>
        <LongName>Division Of Mathematical Sciences</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Leland M. Jameson</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>This research project studies computational methods to recover signals (images) from partial observations, a technique known as compressed sensing. The project addresses an outstanding issue in compressed sensing, in which redundancies or restrictions preclude the successful use of established techniques. The research investigates a class of functions that promote sparsity under robust conditions and can be minimized with efficient or fast algorithms. The computational tools studied in the project will enhance sensing capabilities in applications such as imaging in astronomy and radar, medical imaging, threat detection, and recommender systems. The project provides systematic training of graduate students towards advanced degrees in computational mathematics. The computational methods developed in the project will serve as a valuable tool for information technology and data sciences, benefitting the country and the general public in the digital age.&lt;br/&gt;&lt;br/&gt;The widely used convex function for sparse signal recovery is L1, which is known to introduce bias. This project studies a family of unbiased non-convex sparsity promoting functions called the transformed L1 (TL1). The TL1 minimization under a linear constraint can be solved by iterative thresholding methods with closed-form thresholding functions. The goal is to improve on L1 under robust sensing conditions when the constraint is ill-conditioned or the theoretical guarantees for successful application of the L1 method are not satisfied.</AbstractNarration>
    <MinAmdLetterDate>09/16/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>09/16/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1522383</AwardID>
    <Investigator>
      <FirstName>Jack</FirstName>
      <LastName>Xin</LastName>
      <EmailAddress>jxin@math.uci.edu</EmailAddress>
      <StartDate>09/16/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>University of California-Irvine</Name>
      <CityName>Irvine</CityName>
      <ZipCode>926173067</ZipCode>
      <PhoneNumber>9498244768</PhoneNumber>
      <StreetAddress>5171 California Avenue, Ste 150</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>California</StateName>
      <StateCode>CA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>1271</Code>
      <Text>COMPUTATIONAL MATHEMATICS</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>9263</Code>
      <Text>COMPUTATIONAL SCIENCE &amp; ENGING</Text>
    </ProgramReference>
  </Award>
</rootTag>
