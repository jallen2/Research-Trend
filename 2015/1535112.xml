<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>Collaborative Research: Personalized Benchmarks for High Performance Computing Applications</AwardTitle>
    <AwardEffectiveDate>09/01/2015</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2017</AwardExpirationDate>
    <AwardAmount>191000</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05090000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Div Of Advanced Cyberinfrastructure</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Edward Walker</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>As high-performance computing applications target ever-larger problems, data input and output (I/O) takes up more and more run time. Users, software developers, and platform administrators often find it difficult to understand what an application's I/O code is doing, why it is slow, how it might be improved, or how well it would perform on a different platform. I/O benchmarks help address this problem, but they are expensive to produce and thus are not available for most applications. This project is providing user-friendly personalized I/O benchmarks for all applications, by leveraging existing lightweight I/O profilers that already monitor the behavior of applications on high-performance computing platforms. The resulting personalized benchmarks will help researchers, developers, and purchasers in evaluating potential new storage system architectures, evaluating existing or new versions of storage systems and I/O libraries, planning for purchases, comparing performance of application clusters or workloads across platforms, and improving the performance of parallel I/O libraries and applications. The analytics and benchmark generation software, and example benchmarks, will be publicly released.&lt;br/&gt;&lt;br/&gt;This project uses two methods to construct personalized I/O benchmarks. First, the project is making existing applications self-benchmarking across all of their runs, by providing analytics and visualization facilities to convey to stakeholders the information already automatically captured by lightweight I/O profilers such as Darshan during each run. Second, the project is creating platform-customized benchmark suites that represent the mix of application-level workloads observed on a given platform. To accomplish this, the project is clustering observed production jobs based on their I/O behavior and using both new and existing I/O kernel generation techniques to generate a compact benchmark for each cluster. The resulting benchmark suite will advance the state of the art by serving as a proxy for real-world, platform-specific production I/O workloads, and by providing previously unavailable insight into how prevalent those workloads are at a given facility.</AbstractNarration>
    <MinAmdLetterDate>08/14/2015</MinAmdLetterDate>
    <MaxAmdLetterDate>08/14/2015</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1535112</AwardID>
    <Investigator>
      <FirstName>Robert</FirstName>
      <LastName>Ross</LastName>
      <EmailAddress>rross@mcs.anl.gov</EmailAddress>
      <StartDate>08/14/2015</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Investigator>
      <FirstName>Philip</FirstName>
      <LastName>Carns</LastName>
      <EmailAddress>carns@mcs.anl.gov</EmailAddress>
      <StartDate>08/14/2015</StartDate>
      <EndDate/>
      <RoleCode>Co-Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Northwestern University</Name>
      <CityName>Evanston</CityName>
      <ZipCode>602013149</ZipCode>
      <PhoneNumber>8474913003</PhoneNumber>
      <StreetAddress>1801 Maple Ave.</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Illinois</StateName>
      <StateCode>IL</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7684</Code>
      <Text>STRATEGIC TECHNOLOGIES FOR CI</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>7684</Code>
      <Text>STRATEGIC TECHNOLOGIES FOR CI</Text>
    </ProgramReference>
  </Award>
</rootTag>
