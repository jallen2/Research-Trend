<?xml version="1.0" encoding="UTF-8"?>

<rootTag>
  <Award>
    <AwardTitle>AitF: FULL: Collaborative Research: PEARL: Perceptual Adaptive Representation Learning in the Wild</AwardTitle>
    <AwardEffectiveDate>09/01/2016</AwardEffectiveDate>
    <AwardExpirationDate>08/31/2019</AwardExpirationDate>
    <AwardAmount>173754</AwardAmount>
    <AwardInstrument>
      <Value>Standard Grant</Value>
    </AwardInstrument>
    <Organization>
      <Code>05010000</Code>
      <Directorate>
        <LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
      </Directorate>
      <Division>
        <LongName>Division of Computing and Communication Foundations</LongName>
      </Division>
    </Organization>
    <ProgramOfficer>
      <SignBlockName>Tracy J. Kimbrel</SignBlockName>
    </ProgramOfficer>
    <AbstractNarration>Vast amounts of digitized images and videos are now commonly available, and the advent of search engines has further facilitated their access. This has created an exceptional opportunity for the application of machine learning techniques to model human visual perception. However, the data often does not conform to the core assumption of machine learning that training and test images are drawn from exactly the same distribution, or "domain." In practice, the training and test distributions are often somewhat dissimilar, and distributions may even drift with time. For example, a "dog" detector trained on Flickr may be tested on images from a wearable camera, where dogs are seen in different viewpoints and lighting conditions. The problem of compensating for these changes--the domain adaptation problem--must therefore be addressed both in theory and in practice for algorithms to be effective. This problem is not just a second-order effect and its solution does not constitute a small increase in performance. Ignoring it can lead to dramatically poor results for algorithms "in the field."&lt;br/&gt;&lt;br/&gt;This project will develop a core suite of theory and algorithms for PErceptual Adaptive Representation Learning (PEARL), which, when given a new task domain, and previous experience with related tasks and domains, will provide a learning architecture likely to achieve optimal generalization on the new task. We expect PEARL to have a significant impact on the research community by providing a much-needed theoretical and computational framework that takes steps toward unifying the subfields of domain adaptation theory and domain adaptation practice. Our theoretical and practical advancements will impact many application areas by allowing the use of pre-trained perceptual models (visual and otherwise) in new situations and across space and time. For example, in mobile technology and robotics, PEARL will help personal assistants and robots better adapt their perceptual interfaces to individual users and particular situated environments. At the core of this project are three main research thrusts: 1) making theoretical advances for domain adaptation by developing generalized discrepancy distance minimization; 2) using the theoretical guarantees of generalized discrepancy distance to develop algorithms for key adaptation scenarios of deep perceptual representation learning, domain adaptation with active learning, and time-dependent adaptation; 3) advancing the theory and developing algorithms for the multiple-source adaptation scenario. In addition to our core aims, we plan to implement our algorithms within a scalable open-source framework, and evaluate our algorithms on large-scale visual data sets.</AbstractNarration>
    <MinAmdLetterDate>03/14/2017</MinAmdLetterDate>
    <MaxAmdLetterDate>03/14/2017</MaxAmdLetterDate>
    <ARRAAmount/>
    <AwardID>1723379</AwardID>
    <Investigator>
      <FirstName>Kate</FirstName>
      <LastName>Saenko</LastName>
      <EmailAddress>saenko@bu.edu</EmailAddress>
      <StartDate>03/14/2017</StartDate>
      <EndDate/>
      <RoleCode>Principal Investigator</RoleCode>
    </Investigator>
    <Institution>
      <Name>Trustees of Boston University</Name>
      <CityName>BOSTON</CityName>
      <ZipCode>022151300</ZipCode>
      <PhoneNumber>6173534365</PhoneNumber>
      <StreetAddress>881 COMMONWEALTH AVE</StreetAddress>
      <CountryName>United States</CountryName>
      <StateName>Massachusetts</StateName>
      <StateCode>MA</StateCode>
    </Institution>
    <ProgramElement>
      <Code>7239</Code>
      <Text>Algorithms in the Field</Text>
    </ProgramElement>
    <ProgramReference>
      <Code>012Z</Code>
      <Text>AitF FULL Projects</Text>
    </ProgramReference>
  </Award>
</rootTag>
